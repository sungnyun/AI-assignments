{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReonT_YasRSx"
   },
   "source": [
    "# KAIST AI605 Assignment 3: Transformer\n",
    "\n",
    "TA in charge: Jaehyeong Jo (harryjo97@kaist.ac.kr)\n",
    "\n",
    "**Due date**:  Nov 22 (Mon) 11:00pm, 2021  \n",
    "\n",
    "\n",
    "## Your Submission\n",
    "If you are a KAIST student, you will submit your assignment via [KLMS](https://klms.kaist.ac.kr). If you are a NAVER student, you will submit via [Google Form](https://forms.gle/aGZZ86YpCdv2zEVt9). \n",
    "\n",
    "You need to submit both (1) a PDF of this notebook, and (2) a link to CoLab for execution (.ipynb file is also allowed).\n",
    "\n",
    "Use in-line LaTeX (see below) for mathematical expressions. Collaboration among students is allowed but it is not a group assignment so make sure your answer and code are your own. Make sure to mention your collaborators in your assignment with their names and their student ids.\n",
    "\n",
    "## Grading\n",
    "The entire assignment is out of 20 points. You can obtain up to 3 bonus points (i.e. max score is 23 points). For every late day, your grade will be deducted by 2 points (KAIST students only). You can use one of your no-penalty late days (7 days in total). Make sure to mention this in your submission. You will receive a grade of zero if you submit after 7 days.\n",
    "\n",
    "\n",
    "## Environment\n",
    "You will only use Python 3.7 and PyTorch 1.9, which is already available on Colab:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<<This is a Late Submission !!! (5 days)>>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9qwta269rqLQ",
    "outputId": "d3ad4175-fc1c-44af-907e-eae9490bdeac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.8.3\n",
      "torch 1.7.0\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "import torch\n",
    "\n",
    "print(\"python\", python_version())\n",
    "print(\"torch\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTm5eq4NwQZs"
   },
   "source": [
    "## 1. Attention Layer\n",
    "\n",
    "We will first start with going over a few concepts that you learned in your high school statistics class. The variance of a random variable $X$, $\\text{Var}(X)$ is defined as $\\text{E}[(X-\\mu)^2]$ where $\\mu$ is the mean of $X$. Furthermore, given two independent random variables $X$ and $Y$ and a constant $a$,\n",
    "$$ \\text{Var}(X+Y) = \\text{Var}(X) + \\text{Var}(Y),$$\n",
    "$$ \\text{Var}(aX) = a^2\\text{Var}(X),$$\n",
    "$$ \\text{Var}(XY) = \\text{E}(X^2)\\text{E}(Y^2) - [\\text{E}(X)]^2[\\text{E}(Y)]^2.$$\n",
    "\n",
    "> **Problem 1.1** *(3 points)* Suppose we are given two sets of $n$ random variables, $X_1 \\dots X_n$ and $Y_1 \\dots Y_n$, where all of these $2n$ variables are mutually independent and have a mean of $0$ and a variance of $1$. Prove that\n",
    "$$\\text{Var}\\left(\\sum_i^n X_i Y_i\\right) = n.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer 1.1**\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Var}\\big(\\sum_i^n X_i Y_i\\big) &= \\sum_i^n\\text{Var}(X_i Y_i) ~~ \\text{(by indep.)} \\\\\n",
    "&= \\sum_i^n E(X_i^2)E(Y_i^2) - E(X_i)^2 E(Y_i)^2 \\\\\n",
    "&= \\sum_i^n 1\\cdot 1 - 0 \\cdot 0 \\\\\n",
    "&= n\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KIelEM56jn_"
   },
   "source": [
    "In Lecture 11 and 12, we discussed how the attention is computed in Transformer via the following equation,\n",
    "$$ \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^\\top}{\\sqrt{d_k}}\\right)V.$$\n",
    "> **Problem 1.2** *(3 points)*  Suppose $Q$ and $K$ are matrices of independent variables each of which has a mean of $0$ and a variance of $1$. Using what you learned from Problem 1.1., show that\n",
    "$$\\text{Var}\\left(\\frac{QK^\\top}{\\sqrt{d_k}}\\right) = 1.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer 1.2**\n",
    "\n",
    "Let $Q\\in \\mathbb{R}^{B\\times d_k}$ and $K\\in \\mathbb{R}^{B\\times d_k}$.\n",
    "For every $\\text{Var}(Q_i K_j^\\top), \\forall i,j\\in[B]$, since $Q_i$ and $K_j^\\top$ are mutually independent and have zero mean and unit variance, the following holds:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Var}\\big(\\frac{Q_i K_j^\\top}{\\sqrt{d_k}}\\big) &= \\frac{1}{d_k} \\text{Var}\\big(Q_i K_j^\\top \\big) \\\\\n",
    "&= \\frac{1}{d_k} \\text{Var}\\big(\\sum_{k=1}^{d_k} Q_{ik} K_{kj}^\\top \\big) \\\\\n",
    "&= \\frac{1}{d_k} \\cdot d_k ~~~ \\text{(Problem 1.1)} \\\\ \n",
    "&= 1\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DU3a3FEu6loq"
   },
   "source": [
    "\n",
    "> **Problem 1.3** *(4 points)* What would happen if the assumption that the variance of $Q$ and $K$ is $1$ does not hold? Consider each case of it being higher and lower than $1$ and conjecture what it implies, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Answer 1.3**\n",
    "\n",
    "If the variance of $Q$ and $K$ are higher than $1$,  $\\text{Var}(QK^T) \\ge d_k$. Therefore, scaling with $\\sqrt{d_k}$ may not be a good choice. Therefore, scaling with $\\sqrt{d_k}$ is not good enough; considering the softmax operation in Attention formula, the temperature scale of $\\sqrt{d_k}$ makes a sharp distribution, attending only a few points. On the other hand, if the variance of $Q$ and $K$ are smaller than $1$, $\\text{Var}(QK^T) \\le d_k$. In this case, considering the softmax operation in Attention formula, the temperature scale of $\\sqrt{d_k}$ makes a flat distribution, giving every similar attention scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afEcnAG8Q1Jo"
   },
   "source": [
    "## 2. Transformer\n",
    "\n",
    "In this section, you will implement Transformer for a few tasks that are simpler than machine translation. First, go through [Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html) and make sure you understand every block of the code. Then, you will reuse these code where appropriate to create models for following three tasks. Note that we do not provide a separate training or evaluation data, so it is your job to be able to create these in a reasonable manner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **Problem 2.1** *(4 points)* Create a model that takes a random set of input symbols from a vocabulary of digits (i.e. 0, 1, ... , 8, 9) as the input and generate back the same symbols. Instead of varying length, we fix the length to 32. Make sure to report that your model's accuracy (gives credit only if the entire output sequence is correct) goes above 90%. Note that a similar problem is also in Annotated Transformer, and copying code is allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_context(context=\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many \n",
    "    other models.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask,\n",
    "                            tgt, tgt_mask)\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "    \n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
    "    \n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)\n",
    "\n",
    "    \n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "    \n",
    "\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "    \n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)\n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    " \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)\n",
    "    \n",
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)\n",
    "    \n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "    \n",
    "    \n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n",
    "    \n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(src_vocab, tgt_vocab, N=6, \n",
    "               d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), \n",
    "                             c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab))\n",
    "    \n",
    "    # This was important from their code. \n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform(p)\n",
    "    return model\n",
    "\n",
    "class Batch:\n",
    "    \"Object for holding a batch of data with mask during training.\"\n",
    "    def __init__(self, src, trg=None, pad=0):\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        if trg is not None:\n",
    "            self.trg = trg[:, :-1]\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            self.trg_mask = \\\n",
    "                self.make_std_mask(self.trg, pad)\n",
    "            self.ntokens = (self.trg_y != pad).data.sum()\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & Variable(\n",
    "            subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
    "        return tgt_mask\n",
    "    \n",
    "\n",
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
    "        \n",
    "def get_std_opt(model):\n",
    "    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n",
    "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "\n",
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(size_average=False)\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, Variable(true_dist, requires_grad=False))\n",
    "    \n",
    "class SimpleLossCompute:\n",
    "    \"A simple loss compute and train function.\"\n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "        \n",
    "    def __call__(self, x, y, norm):\n",
    "        seq_len = y.size(-1)\n",
    "        x = self.generator(x)\n",
    "        pred = x.data.max(dim=-1)[1]\n",
    "        correct = ((pred == y).sum(dim=-1) == seq_len).sum().item()\n",
    "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)), \n",
    "                              y.contiguous().view(-1)) / norm\n",
    "        loss.backward()\n",
    "        if self.opt is not None:\n",
    "            self.opt.step()\n",
    "            self.opt.optimizer.zero_grad()\n",
    "        return loss.data * norm, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(V, batch, nbatches):\n",
    "    \"Generate random data for a src-tgt copy task.\"\n",
    "    for i in range(nbatches):\n",
    "        data = torch.from_numpy(np.random.randint(1, V, size=(batch, 33)))\n",
    "        data[:, 0] = 1\n",
    "        src = Variable(data, requires_grad=False)\n",
    "        tgt = Variable(data, requires_grad=False)\n",
    "        yield Batch(src, tgt, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(data_iter, model, loss_compute, epoch):\n",
    "    \"Standard Training and Logging Function\"\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    acc = 0\n",
    "    cnt = 0\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        out = model.forward(batch.src, batch.trg, \n",
    "                            batch.src_mask, batch.trg_mask)\n",
    "        loss, correct = loss_compute(out, batch.trg_y, batch.ntokens)\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        tokens += batch.ntokens\n",
    "        acc += correct\n",
    "        cnt += batch.trg_y.shape[0]\n",
    "        if (i+1) % 20 == 0:\n",
    "            elapsed = time.time() - start\n",
    "            print(\"Epoch: %d Step: %d Loss: %f Tokens per Sec: %f\" %\n",
    "                    (epoch, i+1, loss / batch.ntokens, tokens / elapsed))\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "    return total_loss / total_tokens, acc / cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sungnyun/anaconda3/lib/python3.8/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "<ipython-input-5-5fe0956476b4>:20: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  nn.init.xavier_uniform(p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Step: 20 Loss: 2.292718 Tokens per Sec: 6041.841309\n",
      "Validation Loss: 2.1984, Validation Acc: 0.00%\n",
      "Epoch: 1 Step: 20 Loss: 2.213340 Tokens per Sec: 6070.613281\n",
      "Validation Loss: 2.1488, Validation Acc: 0.00%\n",
      "Epoch: 2 Step: 20 Loss: 2.113729 Tokens per Sec: 6122.917969\n",
      "Validation Loss: 2.1139, Validation Acc: 0.00%\n",
      "Epoch: 3 Step: 20 Loss: 2.154241 Tokens per Sec: 6077.809570\n",
      "Validation Loss: 2.0846, Validation Acc: 0.00%\n",
      "Epoch: 4 Step: 20 Loss: 2.106472 Tokens per Sec: 6212.707520\n",
      "Validation Loss: 2.0769, Validation Acc: 0.00%\n",
      "Epoch: 5 Step: 20 Loss: 2.050679 Tokens per Sec: 6183.625977\n",
      "Validation Loss: 2.0213, Validation Acc: 0.00%\n",
      "Epoch: 6 Step: 20 Loss: 2.006129 Tokens per Sec: 6050.239258\n",
      "Validation Loss: 1.9740, Validation Acc: 0.00%\n",
      "Epoch: 7 Step: 20 Loss: 1.999506 Tokens per Sec: 6232.646973\n",
      "Validation Loss: 1.9442, Validation Acc: 0.00%\n",
      "Epoch: 8 Step: 20 Loss: 1.708790 Tokens per Sec: 6243.300293\n",
      "Validation Loss: 1.4965, Validation Acc: 0.00%\n",
      "Epoch: 9 Step: 20 Loss: 1.723271 Tokens per Sec: 6220.234863\n",
      "Validation Loss: 1.6099, Validation Acc: 0.00%\n",
      "Epoch: 10 Step: 20 Loss: 1.380073 Tokens per Sec: 6154.426270\n",
      "Validation Loss: 1.1224, Validation Acc: 0.00%\n",
      "Epoch: 11 Step: 20 Loss: 1.907574 Tokens per Sec: 6223.563965\n",
      "Validation Loss: 1.8242, Validation Acc: 0.00%\n",
      "Epoch: 12 Step: 20 Loss: 1.677559 Tokens per Sec: 6269.504883\n",
      "Validation Loss: 1.5412, Validation Acc: 0.00%\n",
      "Epoch: 13 Step: 20 Loss: 1.519670 Tokens per Sec: 6226.383301\n",
      "Validation Loss: 1.3235, Validation Acc: 0.00%\n",
      "Epoch: 14 Step: 20 Loss: 1.207654 Tokens per Sec: 6252.952148\n",
      "Validation Loss: 0.9522, Validation Acc: 0.00%\n",
      "Epoch: 15 Step: 20 Loss: 0.944293 Tokens per Sec: 6227.490234\n",
      "Validation Loss: 0.7400, Validation Acc: 0.00%\n",
      "Epoch: 16 Step: 20 Loss: 1.121010 Tokens per Sec: 6222.080078\n",
      "Validation Loss: 0.8646, Validation Acc: 0.00%\n",
      "Epoch: 17 Step: 20 Loss: 0.689292 Tokens per Sec: 6214.712402\n",
      "Validation Loss: 0.4624, Validation Acc: 0.00%\n",
      "Epoch: 18 Step: 20 Loss: 0.622735 Tokens per Sec: 6210.918945\n",
      "Validation Loss: 0.3827, Validation Acc: 0.67%\n",
      "Epoch: 19 Step: 20 Loss: 0.550777 Tokens per Sec: 6191.287109\n",
      "Validation Loss: 0.2856, Validation Acc: 3.33%\n",
      "Epoch: 20 Step: 20 Loss: 0.402400 Tokens per Sec: 6125.035156\n",
      "Validation Loss: 0.1697, Validation Acc: 14.67%\n",
      "Epoch: 21 Step: 20 Loss: 0.254299 Tokens per Sec: 6029.789062\n",
      "Validation Loss: 0.0869, Validation Acc: 39.33%\n",
      "Epoch: 22 Step: 20 Loss: 0.151851 Tokens per Sec: 5955.750488\n",
      "Validation Loss: 0.0604, Validation Acc: 44.00%\n",
      "Epoch: 23 Step: 20 Loss: 0.131954 Tokens per Sec: 5991.244629\n",
      "Validation Loss: 0.0429, Validation Acc: 71.33%\n",
      "Epoch: 24 Step: 20 Loss: 0.142635 Tokens per Sec: 5923.452637\n",
      "Validation Loss: 0.0282, Validation Acc: 71.33%\n",
      "Epoch: 25 Step: 20 Loss: 0.103245 Tokens per Sec: 5965.190918\n",
      "Validation Loss: 0.0268, Validation Acc: 80.67%\n",
      "Epoch: 26 Step: 20 Loss: 0.107378 Tokens per Sec: 5924.616699\n",
      "Validation Loss: 0.0497, Validation Acc: 60.00%\n",
      "Epoch: 27 Step: 20 Loss: 0.088820 Tokens per Sec: 5887.970703\n",
      "Validation Loss: 0.0381, Validation Acc: 72.00%\n",
      "Epoch: 28 Step: 20 Loss: 0.111645 Tokens per Sec: 5734.285645\n",
      "Validation Loss: 0.0332, Validation Acc: 70.00%\n",
      "Epoch: 29 Step: 20 Loss: 0.084944 Tokens per Sec: 5711.217773\n",
      "Validation Loss: 0.0112, Validation Acc: 92.00%\n",
      "Epoch: 30 Step: 20 Loss: 0.075890 Tokens per Sec: 5587.509766\n",
      "Validation Loss: 0.0220, Validation Acc: 78.00%\n",
      "Epoch: 31 Step: 20 Loss: 0.058663 Tokens per Sec: 5637.533203\n",
      "Validation Loss: 0.0080, Validation Acc: 93.33%\n",
      "Epoch: 32 Step: 20 Loss: 0.052396 Tokens per Sec: 5440.664062\n",
      "Validation Loss: 0.0275, Validation Acc: 76.67%\n",
      "Epoch: 33 Step: 20 Loss: 0.057778 Tokens per Sec: 5551.412109\n",
      "Validation Loss: 0.0200, Validation Acc: 81.33%\n",
      "Epoch: 34 Step: 20 Loss: 0.119597 Tokens per Sec: 5515.170898\n",
      "Validation Loss: 0.0142, Validation Acc: 87.33%\n",
      "Epoch: 35 Step: 20 Loss: 0.104406 Tokens per Sec: 5296.281250\n",
      "Validation Loss: 0.0178, Validation Acc: 89.33%\n",
      "Epoch: 36 Step: 20 Loss: 0.041032 Tokens per Sec: 4613.054199\n",
      "Validation Loss: 0.0083, Validation Acc: 92.00%\n",
      "Epoch: 37 Step: 20 Loss: 0.055340 Tokens per Sec: 4179.380371\n",
      "Validation Loss: 0.0274, Validation Acc: 78.67%\n",
      "Epoch: 38 Step: 20 Loss: 0.063703 Tokens per Sec: 4418.728516\n",
      "Validation Loss: 0.0120, Validation Acc: 88.00%\n",
      "Epoch: 39 Step: 20 Loss: 0.072006 Tokens per Sec: 4192.512695\n",
      "Validation Loss: 0.0061, Validation Acc: 95.33%\n",
      "Epoch: 40 Step: 20 Loss: 0.049078 Tokens per Sec: 4066.876953\n",
      "Validation Loss: 0.0119, Validation Acc: 90.00%\n",
      "Epoch: 41 Step: 20 Loss: 0.066630 Tokens per Sec: 3994.974365\n",
      "Validation Loss: 0.0112, Validation Acc: 90.67%\n",
      "Epoch: 42 Step: 20 Loss: 0.044727 Tokens per Sec: 3870.378418\n",
      "Validation Loss: 0.0167, Validation Acc: 86.00%\n",
      "Epoch: 43 Step: 20 Loss: 0.026363 Tokens per Sec: 3604.613281\n",
      "Validation Loss: 0.0068, Validation Acc: 92.00%\n",
      "Epoch: 44 Step: 20 Loss: 0.019874 Tokens per Sec: 3566.242188\n",
      "Validation Loss: 0.0051, Validation Acc: 96.00%\n",
      "Epoch: 45 Step: 20 Loss: 0.043552 Tokens per Sec: 3579.613525\n",
      "Validation Loss: 0.0069, Validation Acc: 95.33%\n",
      "Epoch: 46 Step: 20 Loss: 0.045021 Tokens per Sec: 3526.715576\n",
      "Validation Loss: 0.0072, Validation Acc: 94.67%\n",
      "Epoch: 47 Step: 20 Loss: 0.060334 Tokens per Sec: 3318.684082\n",
      "Validation Loss: 0.0208, Validation Acc: 80.67%\n",
      "Epoch: 48 Step: 20 Loss: 0.017947 Tokens per Sec: 3484.596924\n",
      "Validation Loss: 0.0036, Validation Acc: 96.67%\n",
      "Epoch: 49 Step: 20 Loss: 0.039517 Tokens per Sec: 3452.861328\n",
      "Validation Loss: 0.0100, Validation Acc: 88.00%\n",
      "Epoch: 50 Step: 20 Loss: 0.031835 Tokens per Sec: 3398.649414\n",
      "Validation Loss: 0.0099, Validation Acc: 93.33%\n",
      "Epoch: 51 Step: 20 Loss: 0.016612 Tokens per Sec: 3538.441650\n",
      "Validation Loss: 0.0098, Validation Acc: 91.33%\n",
      "Epoch: 52 Step: 20 Loss: 0.025570 Tokens per Sec: 3634.822998\n",
      "Validation Loss: 0.0070, Validation Acc: 93.33%\n",
      "Epoch: 53 Step: 20 Loss: 0.053554 Tokens per Sec: 3588.864990\n",
      "Validation Loss: 0.0238, Validation Acc: 80.00%\n",
      "Epoch: 54 Step: 20 Loss: 0.040647 Tokens per Sec: 3496.999512\n",
      "Validation Loss: 0.0022, Validation Acc: 98.00%\n",
      "Epoch: 55 Step: 20 Loss: 0.028060 Tokens per Sec: 3448.916260\n",
      "Validation Loss: 0.0019, Validation Acc: 98.00%\n",
      "Epoch: 56 Step: 20 Loss: 0.044370 Tokens per Sec: 3358.057373\n",
      "Validation Loss: 0.0084, Validation Acc: 95.33%\n",
      "Epoch: 57 Step: 20 Loss: 0.037871 Tokens per Sec: 3381.295410\n",
      "Validation Loss: 0.0077, Validation Acc: 94.00%\n",
      "Epoch: 58 Step: 20 Loss: 0.015135 Tokens per Sec: 3324.985840\n",
      "Validation Loss: 0.0046, Validation Acc: 94.00%\n",
      "Epoch: 59 Step: 20 Loss: 0.024038 Tokens per Sec: 3315.074463\n",
      "Validation Loss: 0.0040, Validation Acc: 96.67%\n",
      "Epoch: 60 Step: 20 Loss: 0.067089 Tokens per Sec: 3333.395508\n",
      "Validation Loss: 0.0073, Validation Acc: 91.33%\n",
      "Epoch: 61 Step: 20 Loss: 0.017708 Tokens per Sec: 3268.923096\n",
      "Validation Loss: 0.0053, Validation Acc: 97.33%\n",
      "Epoch: 62 Step: 20 Loss: 0.014599 Tokens per Sec: 3341.951172\n",
      "Validation Loss: 0.0017, Validation Acc: 98.67%\n",
      "Epoch: 63 Step: 20 Loss: 0.025191 Tokens per Sec: 3496.516357\n",
      "Validation Loss: 0.0018, Validation Acc: 98.67%\n",
      "Epoch: 64 Step: 20 Loss: 0.026372 Tokens per Sec: 3407.743652\n",
      "Validation Loss: 0.0071, Validation Acc: 95.33%\n",
      "Epoch: 65 Step: 20 Loss: 0.006839 Tokens per Sec: 3438.436279\n",
      "Validation Loss: 0.0043, Validation Acc: 95.33%\n",
      "Epoch: 66 Step: 20 Loss: 0.004360 Tokens per Sec: 3355.526855\n",
      "Validation Loss: 0.0027, Validation Acc: 97.33%\n",
      "Epoch: 67 Step: 20 Loss: 0.017144 Tokens per Sec: 3384.563965\n",
      "Validation Loss: 0.0010, Validation Acc: 99.33%\n",
      "Epoch: 68 Step: 20 Loss: 0.014897 Tokens per Sec: 3278.699707\n",
      "Validation Loss: 0.0017, Validation Acc: 98.67%\n",
      "Epoch: 69 Step: 20 Loss: 0.040671 Tokens per Sec: 3218.296631\n",
      "Validation Loss: 0.0040, Validation Acc: 96.00%\n",
      "Epoch: 70 Step: 20 Loss: 0.024125 Tokens per Sec: 3299.912354\n",
      "Validation Loss: 0.0037, Validation Acc: 98.00%\n",
      "Epoch: 71 Step: 20 Loss: 0.013309 Tokens per Sec: 3357.751953\n",
      "Validation Loss: 0.0033, Validation Acc: 95.33%\n",
      "Epoch: 72 Step: 20 Loss: 0.019307 Tokens per Sec: 3485.481201\n",
      "Validation Loss: 0.0034, Validation Acc: 98.67%\n",
      "Epoch: 73 Step: 20 Loss: 0.022947 Tokens per Sec: 3528.917236\n",
      "Validation Loss: 0.0009, Validation Acc: 99.33%\n",
      "Epoch: 74 Step: 20 Loss: 0.013794 Tokens per Sec: 3420.325684\n",
      "Validation Loss: 0.0011, Validation Acc: 100.00%\n",
      "Epoch: 75 Step: 20 Loss: 0.031032 Tokens per Sec: 3348.551270\n",
      "Validation Loss: 0.0064, Validation Acc: 93.33%\n",
      "Epoch: 76 Step: 20 Loss: 0.028775 Tokens per Sec: 3435.060059\n",
      "Validation Loss: 0.0029, Validation Acc: 97.33%\n",
      "Epoch: 77 Step: 20 Loss: 0.010420 Tokens per Sec: 3289.468994\n",
      "Validation Loss: 0.0007, Validation Acc: 98.67%\n",
      "Epoch: 78 Step: 20 Loss: 0.027443 Tokens per Sec: 3389.405518\n",
      "Validation Loss: 0.0008, Validation Acc: 100.00%\n",
      "Epoch: 79 Step: 20 Loss: 0.017726 Tokens per Sec: 3352.237793\n",
      "Validation Loss: 0.0082, Validation Acc: 90.00%\n",
      "Epoch: 80 Step: 20 Loss: 0.013686 Tokens per Sec: 3336.656738\n",
      "Validation Loss: 0.0006, Validation Acc: 100.00%\n",
      "Epoch: 81 Step: 20 Loss: 0.014543 Tokens per Sec: 3355.456055\n",
      "Validation Loss: 0.0020, Validation Acc: 98.00%\n",
      "Epoch: 82 Step: 20 Loss: 0.008503 Tokens per Sec: 3329.368164\n",
      "Validation Loss: 0.0010, Validation Acc: 99.33%\n",
      "Epoch: 83 Step: 20 Loss: 0.020764 Tokens per Sec: 3447.933350\n",
      "Validation Loss: 0.0006, Validation Acc: 100.00%\n",
      "Epoch: 84 Step: 20 Loss: 0.019289 Tokens per Sec: 3430.149658\n",
      "Validation Loss: 0.0010, Validation Acc: 99.33%\n",
      "Epoch: 85 Step: 20 Loss: 0.001286 Tokens per Sec: 3373.646484\n",
      "Validation Loss: 0.0020, Validation Acc: 98.00%\n",
      "Epoch: 86 Step: 20 Loss: 0.015896 Tokens per Sec: 3399.944336\n",
      "Validation Loss: 0.0013, Validation Acc: 99.33%\n",
      "Epoch: 87 Step: 20 Loss: 0.004553 Tokens per Sec: 3353.735840\n",
      "Validation Loss: 0.0004, Validation Acc: 100.00%\n",
      "Epoch: 88 Step: 20 Loss: 0.009902 Tokens per Sec: 3435.781006\n",
      "Validation Loss: 0.0052, Validation Acc: 94.67%\n",
      "Epoch: 89 Step: 20 Loss: 0.023687 Tokens per Sec: 3421.135742\n",
      "Validation Loss: 0.0050, Validation Acc: 96.67%\n",
      "Epoch: 90 Step: 20 Loss: 0.020975 Tokens per Sec: 3297.374268\n",
      "Validation Loss: 0.0007, Validation Acc: 99.33%\n",
      "Epoch: 91 Step: 20 Loss: 0.039933 Tokens per Sec: 3293.447998\n",
      "Validation Loss: 0.0002, Validation Acc: 100.00%\n",
      "Epoch: 92 Step: 20 Loss: 0.003902 Tokens per Sec: 3363.353760\n",
      "Validation Loss: 0.0178, Validation Acc: 90.00%\n",
      "Epoch: 93 Step: 20 Loss: 0.006548 Tokens per Sec: 3430.113281\n",
      "Validation Loss: 0.0008, Validation Acc: 99.33%\n",
      "Epoch: 94 Step: 20 Loss: 0.008626 Tokens per Sec: 3401.906494\n",
      "Validation Loss: 0.0105, Validation Acc: 94.00%\n",
      "Epoch: 95 Step: 20 Loss: 0.021188 Tokens per Sec: 3405.308350\n",
      "Validation Loss: 0.0028, Validation Acc: 97.33%\n",
      "Epoch: 96 Step: 20 Loss: 0.002150 Tokens per Sec: 3404.058838\n",
      "Validation Loss: 0.0003, Validation Acc: 100.00%\n",
      "Epoch: 97 Step: 20 Loss: 0.001807 Tokens per Sec: 3443.018555\n",
      "Validation Loss: 0.0001, Validation Acc: 100.00%\n",
      "Epoch: 98 Step: 20 Loss: 0.007447 Tokens per Sec: 3385.051758\n",
      "Validation Loss: 0.0014, Validation Acc: 98.00%\n",
      "Epoch: 99 Step: 20 Loss: 0.020616 Tokens per Sec: 3402.310059\n",
      "Validation Loss: 0.0004, Validation Acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Train the simple copy task.\n",
    "V = 10\n",
    "criterion = LabelSmoothing(size=V, padding_idx=0, smoothing=0.0)\n",
    "model = make_model(V, V, N=2)\n",
    "model_opt = NoamOpt(model.src_embed[0].d_model, 1, 400,\n",
    "        torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    run_epoch(data_gen(V, 30, 20), model, \n",
    "              SimpleLossCompute(model.generator, criterion, model_opt), epoch)\n",
    "    model.eval()\n",
    "    loss, acc = run_epoch(data_gen(V, 30, 5), model, \n",
    "                    SimpleLossCompute(model.generator, criterion, None), epoch)\n",
    "    print('Validation Loss: {:.4f}, Validation Acc: {:.2f}%'.format(loss, acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> **Problem 2.2** *(6 points)* Now, we will implement a bit more useful function, so-called spelling error correction. Your job is to create a model whose input is a word with spelling errors, and the output is the spelling-corrected word. Here, your vocabulary will be character instead of word. You can create your own training data by using an existing text corpus as the target and inject noise into it to use it as the input. You are free to use whichever text corpus you like. If you can't think of one, please use context data in SQuAD Dataset (see Assignment 2). Report accuracy in your own evaluation data (you will receive full credit as long as both the evaluation data and the accuracy are reasonable), and also show 5 examples where it succeeds at correcting spelling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer 2.2** I used SQuAD validation set. The training set is the words from 'context' in SQuAD, and the evaluation set is the words from 'question' in SQuAD. Evaluation accuracy for spelling check is **21.3%**. Also, see the code below for 5 examples of correcting spelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/sungnyun/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4cd2f17de9407ab0bf2cc2530cefa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answers': {'answer_start': [177, 177, 177],\n",
      "             'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos']},\n",
      " 'context': 'Super Bowl 50 was an American football game to determine the '\n",
      "            'champion of the National Football League (NFL) for the 2015 '\n",
      "            'season. The American Football Conference (AFC) champion Denver '\n",
      "            'Broncos defeated the National Football Conference (NFC) champion '\n",
      "            'Carolina Panthers 24–10 to earn their third Super Bowl title. The '\n",
      "            \"game was played on February 7, 2016, at Levi's Stadium in the San \"\n",
      "            'Francisco Bay Area at Santa Clara, California. As this was the '\n",
      "            '50th Super Bowl, the league emphasized the \"golden anniversary\" '\n",
      "            'with various gold-themed initiatives, as well as temporarily '\n",
      "            'suspending the tradition of naming each Super Bowl game with '\n",
      "            'Roman numerals (under which the game would have been known as '\n",
      "            '\"Super Bowl L\"), so that the logo could prominently feature the '\n",
      "            'Arabic numerals 50.',\n",
      " 'id': '56be4db0acb8001400a502ec',\n",
      " 'question': 'Which NFL team represented the AFC at Super Bowl 50?',\n",
      " 'title': 'Super_Bowl_50'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from pprint import pprint\n",
    "\n",
    "squad_dataset = load_dataset('squad')\n",
    "pprint(squad_dataset['validation'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10570/10570 [00:07<00:00, 1355.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8467 15634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "words = list()\n",
    "test_words = list()\n",
    "\n",
    "for i in tqdm(range(len(squad_dataset['validation']))):\n",
    "    context = squad_dataset['validation'][i]['context'].split(' ')\n",
    "    question = squad_dataset['validation'][i]['question'].split(' ')\n",
    "    for word, test_word in zip(context, question): \n",
    "        if word not in words:\n",
    "            words.append(word)\n",
    "        if test_word not in test_words:\n",
    "            test_words.append(test_word)\n",
    "\n",
    "#answer = copy.deepcopy(words)\n",
    "print(len(words), len(test_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list([chr(i) for i in range(ord('a'),ord('z')+1)])\n",
    "vocab += ['UNK', 'PAD']\n",
    "char2id = {char: i for i, char in enumerate(vocab)} \n",
    "id2char = {i : char for i, char in enumerate(vocab)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8467/8467 [00:00<00:00, 298580.56it/s]\n",
      "100%|██████████| 15634/15634 [00:00<00:00, 295495.71it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "\n",
    "class SentenceBatch(Dataset):\n",
    "    def __init__(self, src, target, pad=27):\n",
    "        src = torch.Tensor(src)\n",
    "        target = torch.Tensor(target)\n",
    "        assert src.shape == target.shape\n",
    "        \n",
    "        self.src = torch.ones(src.size(0), src.size(1)+1)\n",
    "        self.src[:, 1:] = src\n",
    "        self.src = self.src.long()\n",
    "        \n",
    "        self.target = torch.ones(target.size(0), target.size(1)+1)\n",
    "        self.target[:, 1:] = target\n",
    "        self.target = self.target.long()\n",
    "        \n",
    "        self.src_mask = (self.src != pad).unsqueeze(-2)\n",
    "        \n",
    "        self.trg = self.target[:, :-1]\n",
    "        self.trg_y = self.target[:, 1:]\n",
    "        self.trg_mask = self.make_std_mask(self.trg, pad)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.src[idx]\n",
    "        trg = self.trg[idx]\n",
    "        trg_y = self.trg_y[idx]\n",
    "        src_mask = torch.tensor(self.src_mask[idx], dtype=torch.int64)\n",
    "        trg_mask = torch.tensor(self.trg_mask[idx], dtype=torch.int64)\n",
    "\n",
    "        return src, trg, trg_y, src_mask, trg_mask\n",
    "\n",
    "    @staticmethod\n",
    "    def make_std_mask(trg, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        trg_mask = (trg != pad).unsqueeze(-2)\n",
    "        trg_mask = trg_mask & Variable(\n",
    "            subsequent_mask(trg.size(-1)).type_as(trg_mask.data))\n",
    "        return trg_mask\n",
    "\n",
    "    \n",
    "length = 32\n",
    "train_src = []\n",
    "train_trg = []\n",
    "\n",
    "for word in tqdm(words):\n",
    "    trg_id = [char2id[char] if char in char2id else 26 for char in word.lower()]\n",
    "    wordlen = len(trg_id)\n",
    "    src_id = trg_id[:]\n",
    "    if wordlen >= 2:\n",
    "        rand1 = random.randint(0, wordlen-1)\n",
    "        rand2 = random.randint(0, 25)\n",
    "        src_id[rand1] = rand2\n",
    "    if wordlen < length:\n",
    "        src_id += (length - wordlen) * [27] \n",
    "        trg_id += (length - wordlen) * [27]\n",
    "    elif wordlen > length:\n",
    "        src_id = src_id[:length]\n",
    "        trg_id = trg_id[:length]\n",
    "    train_src.append(src_id)\n",
    "    train_trg.append(trg_id)\n",
    "    \n",
    "test_src = []\n",
    "test_trg = []\n",
    "\n",
    "for word in tqdm(test_words):\n",
    "    trg_id = [char2id[char] if char in char2id else 26 for char in word.lower()]\n",
    "    wordlen = len(trg_id)\n",
    "    src_id = trg_id[:]\n",
    "    if wordlen >= 2:\n",
    "        rand1 = random.randint(0, wordlen-1)\n",
    "        rand2 = random.randint(0, 25)\n",
    "        src_id[rand1] = rand2\n",
    "    if wordlen < length:\n",
    "        src_id += (length - wordlen) * [27] \n",
    "        trg_id += (length - wordlen) * [27]\n",
    "    elif wordlen > length:\n",
    "        src_id = src_id[:length]\n",
    "        trg_id = trg_id[:length]\n",
    "    test_src.append(src_id)\n",
    "    test_trg.append(trg_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = SentenceBatch(train_src, train_trg)\n",
    "testset = SentenceBatch(test_src, test_trg)\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    \"A simple loss compute and train function.\"\n",
    "    def __init__(self, criterion, opt=None):\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "        \n",
    "    def __call__(self, x, y, norm):\n",
    "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)), \n",
    "                              y.contiguous().view(-1)) / norm\n",
    "        loss.backward()\n",
    "        if self.opt is not None:\n",
    "            self.opt.step()\n",
    "            self.opt.optimizer.zero_grad()\n",
    "        return loss.data * norm\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-5fe0956476b4>:20: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  nn.init.xavier_uniform(p)\n",
      "<ipython-input-12-874b4246d396>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  src_mask = torch.tensor(self.src_mask[idx], dtype=torch.int64)\n",
      "<ipython-input-12-874b4246d396>:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  trg_mask = torch.tensor(self.trg_mask[idx], dtype=torch.int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 0.6295, Train Acc: 4.71%\n",
      "Epoch: 0, Test Acc: 3.33%\n",
      "Epoch: 1, Train Loss: 0.3621, Train Acc: 6.40%\n",
      "Epoch: 1, Test Acc: 5.51%\n",
      "Epoch: 2, Train Loss: 0.2315, Train Acc: 9.31%\n",
      "Epoch: 2, Test Acc: 9.05%\n",
      "Epoch: 3, Train Loss: 0.1734, Train Acc: 12.63%\n",
      "Epoch: 3, Test Acc: 12.05%\n",
      "Epoch: 4, Train Loss: 0.1554, Train Acc: 14.99%\n",
      "Epoch: 4, Test Acc: 12.51%\n",
      "Epoch: 5, Train Loss: 0.1491, Train Acc: 16.13%\n",
      "Epoch: 5, Test Acc: 13.94%\n",
      "Epoch: 6, Train Loss: 0.1416, Train Acc: 17.40%\n",
      "Epoch: 6, Test Acc: 15.32%\n",
      "Epoch: 7, Train Loss: 0.1414, Train Acc: 18.29%\n",
      "Epoch: 7, Test Acc: 14.95%\n",
      "Epoch: 8, Train Loss: 0.1413, Train Acc: 18.25%\n",
      "Epoch: 8, Test Acc: 12.43%\n",
      "Epoch: 9, Train Loss: 0.1467, Train Acc: 18.29%\n",
      "Epoch: 9, Test Acc: 14.98%\n",
      "Epoch: 10, Train Loss: 0.1424, Train Acc: 18.13%\n",
      "Epoch: 10, Test Acc: 15.98%\n",
      "Epoch: 11, Train Loss: 0.1490, Train Acc: 16.90%\n",
      "Epoch: 11, Test Acc: 13.94%\n",
      "Epoch: 12, Train Loss: 0.1487, Train Acc: 17.01%\n",
      "Epoch: 12, Test Acc: 13.51%\n",
      "Epoch: 13, Train Loss: 0.1438, Train Acc: 17.54%\n",
      "Epoch: 13, Test Acc: 14.53%\n",
      "Epoch: 14, Train Loss: 0.1595, Train Acc: 15.40%\n",
      "Epoch: 14, Test Acc: 15.16%\n",
      "Epoch: 15, Train Loss: 0.1424, Train Acc: 17.44%\n",
      "Epoch: 15, Test Acc: 15.46%\n",
      "Epoch: 16, Train Loss: 0.1315, Train Acc: 20.16%\n",
      "Epoch: 16, Test Acc: 16.48%\n",
      "Epoch: 17, Train Loss: 0.1363, Train Acc: 18.80%\n",
      "Epoch: 17, Test Acc: 16.03%\n",
      "Epoch: 18, Train Loss: 0.1388, Train Acc: 19.36%\n",
      "Epoch: 18, Test Acc: 15.94%\n",
      "Epoch: 19, Train Loss: 0.1295, Train Acc: 20.68%\n",
      "Epoch: 19, Test Acc: 17.23%\n",
      "Epoch: 20, Train Loss: 0.1286, Train Acc: 21.19%\n",
      "Epoch: 20, Test Acc: 17.55%\n",
      "Epoch: 21, Train Loss: 0.1253, Train Acc: 21.63%\n",
      "Epoch: 21, Test Acc: 18.54%\n",
      "Epoch: 22, Train Loss: 0.1203, Train Acc: 22.50%\n",
      "Epoch: 22, Test Acc: 18.17%\n",
      "Epoch: 23, Train Loss: 0.1138, Train Acc: 24.03%\n",
      "Epoch: 23, Test Acc: 20.30%\n",
      "Epoch: 24, Train Loss: 0.1103, Train Acc: 25.55%\n",
      "Epoch: 24, Test Acc: 19.32%\n",
      "Epoch: 25, Train Loss: 0.1128, Train Acc: 25.11%\n",
      "Epoch: 25, Test Acc: 19.73%\n",
      "Epoch: 26, Train Loss: 0.1176, Train Acc: 23.77%\n",
      "Epoch: 26, Test Acc: 20.49%\n",
      "Epoch: 27, Train Loss: 0.1148, Train Acc: 25.17%\n",
      "Epoch: 27, Test Acc: 16.85%\n",
      "Epoch: 28, Train Loss: 0.1154, Train Acc: 24.88%\n",
      "Epoch: 28, Test Acc: 20.54%\n",
      "Epoch: 29, Train Loss: 0.0999, Train Acc: 29.66%\n",
      "Epoch: 29, Test Acc: 21.30%\n"
     ]
    }
   ],
   "source": [
    "V = 28\n",
    "criterion = LabelSmoothing(size=V, padding_idx=27, smoothing=0.0)\n",
    "model = make_model(V, V, N=2)\n",
    "model_opt = NoamOpt(model.src_embed[0].d_model, 1, 400,\n",
    "        torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "loss_compute = SimpleLossCompute(criterion, opt=model_opt)\n",
    "model.cuda()\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_ntokens = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, batch in enumerate(train_loader):\n",
    "        src, trg, trg_y, src_mask, trg_mask = batch\n",
    "        src, trg, trg_y, src_mask, trg_mask = src.cuda(), trg.cuda(), trg_y.cuda(), src_mask.cuda(), trg_mask.cuda()\n",
    "        out = model.generator(model.forward(src, trg, src_mask, trg_mask))\n",
    "        \n",
    "        pred = out.data.max(dim=-1)[1]\n",
    "        correct += ((pred*src_mask.squeeze()[:,1:] == (trg_y*src_mask.squeeze()[:,1:])).sum(dim=-1) == 32).cpu().sum().item()\n",
    "        loss = loss_compute(out, trg_y, trg_y.size(0)*trg_y.size(1))\n",
    "        \n",
    "        total_loss += loss \n",
    "        total_ntokens += trg_y.size(0)*trg_y.size(1)\n",
    "        total += trg.size(0)\n",
    "        \n",
    "    print('Epoch: {:d}, Train Loss: {:.4f}, Train Acc: {:.2f}%'.format(epoch, total_loss/total_ntokens, correct/total*100))\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            src, trg, trg_y, src_mask, trg_mask = batch        \n",
    "            src, trg, trg_y, src_mask, trg_mask = src.cuda(), trg.cuda(), trg_y.cuda(), src_mask.cuda(), trg_mask.cuda()\n",
    "            out = model.generator(model.forward(src, trg, src_mask, trg_mask))\n",
    "            \n",
    "            pred = out.data.max(dim=-1)[1]\n",
    "            correct += ((pred*src_mask.squeeze()[:,1:] == (trg_y*src_mask.squeeze()[:,1:])).sum(dim=-1) == 32).cpu().sum().item()\n",
    "            total += trg.size(0)\n",
    "    print('Epoch: {:d}, Test Acc: {:.2f}%'.format(epoch, correct/total*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source 0:  ['p', 'e', 'r', 'k', 'o', 'r', 'm', 'e', 'd']\n",
      "Target 0:  ['p', 'e', 'r', 'f', 'o', 'r', 'm', 'e', 'd']\n",
      "Source 1:  ['l', 'i', 's', 'r']\n",
      "Target 1:  ['l', 'i', 's', 't']\n",
      "Source 2:  ['s', 't', 'a', 't', 'i', 'o', 'v']\n",
      "Target 2:  ['s', 't', 'a', 't', 'i', 'o', 'n']\n",
      "Source 3:  ['UNK', 'UNK', 'e']\n",
      "Target 3:  ['UNK', 'UNK', 'UNK']\n",
      "Source 4:  ['c', 'a', 'm', 'r']\n",
      "Target 4:  ['c', 'a', 'm', 'e']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-874b4246d396>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  src_mask = torch.tensor(self.src_mask[idx], dtype=torch.int64)\n",
      "<ipython-input-12-874b4246d396>:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  trg_mask = torch.tensor(self.trg_mask[idx], dtype=torch.int64)\n",
      "<ipython-input-17-f5501da0ae34>:13: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729096996/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  idx = (correct == 1).nonzero()[-5:]\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "cnt = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        src, trg, trg_y, src_mask, trg_mask = batch        \n",
    "        src, trg, trg_y, src_mask, trg_mask = src.cuda(), trg.cuda(), trg_y.cuda(), src_mask.cuda(), trg_mask.cuda()\n",
    "        out = model.generator(model.forward(src, trg, src_mask, trg_mask))\n",
    "\n",
    "        pred = out.data.max(dim=-1)[1]\n",
    "        correct = ((pred*src_mask.squeeze()[:,1:] == (trg_y*src_mask.squeeze()[:,1:])).sum(dim=-1) == 32)\n",
    "        idx = (correct == 1).nonzero()[-5:]\n",
    "        \n",
    "        src = src[idx].squeeze()[:, 1:].cpu().numpy()\n",
    "        pred = pred[idx].squeeze().cpu().numpy()\n",
    "        src_mask = src_mask[idx].squeeze()[:, 1:].cpu().numpy()\n",
    "        length = src_mask.sum(-1)\n",
    "        \n",
    "        for j in range(len(src)):\n",
    "            print(f'Source {j}: ', [id2char[id_] for id_ in src[j]][:length[j]])\n",
    "            print(f'Target {j}: ', [id2char[id_] for id_ in pred[j]][:length[j]])\n",
    "            \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "KAIST AI605 Assignment 3.ipynb의 사본",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
