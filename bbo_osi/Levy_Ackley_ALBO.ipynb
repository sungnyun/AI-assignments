{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/sungnyun/custom_turbo/\")\n",
    "#sys.path.insert(0, \"/home/nakyil/jupyter/git_repo/bbo/custom_turbo/\")\n",
    "\n",
    "from turbo import Turbo1\n",
    "from turbo.utils import from_unit_cube, latin_hypercube, to_unit_cube\n",
    "\n",
    "from bayesmark.abstract_optimizer import AbstractOptimizer\n",
    "from bayesmark.experiment import experiment_main\n",
    "from bayesmark.space import JointSpace\n",
    "from sklearn import svm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MaxAbsScaler, RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import time\n",
    "import torch\n",
    "\n",
    "\n",
    "def order_stats(X):\n",
    "    _, idx, cnt = np.unique(X, return_inverse=True, return_counts=True)\n",
    "    obs = np.cumsum(cnt)  # Need to do it this way due to ties\n",
    "    o_stats = obs[idx]\n",
    "    return o_stats\n",
    "\n",
    "\n",
    "def copula_standardize(X):\n",
    "    X = np.nan_to_num(np.asarray(X))  # Replace inf by something large\n",
    "    assert X.ndim == 1 and np.all(np.isfinite(X))\n",
    "    o_stats = order_stats(X)\n",
    "    quantile = np.true_divide(o_stats, len(X) + 1)\n",
    "    X_ss = ss.norm.ppf(quantile)\n",
    "    return X_ss\n",
    "\n",
    "def softmax(a) :\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    \n",
    "    return y\n",
    "\n",
    "def reject_outliers(data, m=.05):\n",
    "    up = np.quantile(data, q=1.-m)\n",
    "    up_list = data < up\n",
    "\n",
    "    return up_list\n",
    "#data - np.mean(data) < m * np.std(data)\n",
    "\n",
    "\n",
    "\n",
    "class AdvancedTurbo:\n",
    "\n",
    "    def __init__(self, api_config, **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        api_config : dict-like of dict-like\n",
    "            Configuration of the optimization variables. See API description.\n",
    "        \"\"\"\n",
    "        self.space_x = JointSpace(api_config)\n",
    "        \n",
    "        reference = {}\n",
    "        for i, orig_key in enumerate(self.space_x.param_list):\n",
    "            reference[i] = orig_key\n",
    "        self.api_config = {param_name:api_config[param_name] for _, param_name in sorted(reference.items())}\n",
    "        \n",
    "        return_true_dim_dict = {}\n",
    "        previous = 0\n",
    "        for idx1, b in enumerate(self.space_x.blocks): \n",
    "            for val in range(previous, b): \n",
    "                return_true_dim_dict[val] = idx1\n",
    "            previous = b\n",
    "        self.return_true_dim = return_true_dim_dict\n",
    "        \n",
    "        self.bounds = self.space_x.get_bounds()\n",
    "        self.lb, self.ub = self.bounds[:, 0], self.bounds[:, 1]\n",
    "        self.dim = len(self.bounds)\n",
    "        self.max_evals = np.iinfo(np.int32).max  # NOTE: Largest possible int\n",
    "        self.batch_size = None\n",
    "        self.history = []\n",
    "        self.epoch = 0\n",
    "        self.int_dim, self.bool_dim, self.float_dim, self.cat_dim, self.cat_loc = self.find_loc()\n",
    "\n",
    "        self._mab_var = ['bool','cat'] #['int'] \n",
    "        self.params = self.initialize_mab()\n",
    "\n",
    "        self._discount = 1.0\n",
    "        self.adapt_region = None\n",
    "\n",
    "        self.turbo = Turbo1(\n",
    "            f=None,\n",
    "            lb=self.bounds[:, 0],\n",
    "            ub=self.bounds[:, 1],\n",
    "            n_init= max(30,2 * self.dim + 1),\n",
    "            max_evals=self.max_evals,\n",
    "            batch_size=1,  # We need to update this later\n",
    "            verbose=False,\n",
    "        )\n",
    "        \n",
    "        self.span = 2 ** (1)\n",
    "        self.squeeze = 2 ** (-1)\n",
    "        \n",
    "        self.classifier = make_pipeline(RobustScaler(),svm.SVC(kernel='rbf'))\n",
    "        self.selected_label = None\n",
    "        self.initiated = False\n",
    "\n",
    "        # values for UCB\n",
    "        self.c_p = 0 # percentage of max function value\n",
    "        \n",
    "    def select_region_by_ucb(self,y,labels):\n",
    "        y_1 = y[np.where(labels==np.unique(labels)[0])]\n",
    "        y_2 = y[np.where(labels==np.unique(labels)[1])]\n",
    "        ucb1 = - y_1.mean()/len(y_1) - self.c_p*y[(-y).argmax().item()]*np.sqrt(2*np.log(len(y))/len(y_1))\n",
    "        ucb2 = - y_2.mean()/len(y_2) - self.c_p*y[(-y).argmax().item()]*np.sqrt(2*np.log(len(y))/len(y_2))\n",
    "        selected_label = np.argmax([ucb1,ucb2])           \n",
    "        return selected_label\n",
    "    \n",
    "\n",
    "    def train_classifier(self,X,fX):\n",
    "        fX[np.isinf(fX) == True] = np.nanmax(fX[fX!=np.inf]) #replace inf to max value in hand\n",
    "        \n",
    "        data_points = np.hstack((X,fX))\n",
    "        mas = RobustScaler()\n",
    "        rescaled_data = mas.fit_transform(data_points)\n",
    "        rescaled_data[:,-1] *= np.sqrt(self.dim) #rescaled for fX\n",
    "#         data_points = fX\n",
    "#         data_points = fX[np.where(reject_outliers(fX))]\n",
    "#         data_points = np.expand_dims(data_points, axis=-1)\n",
    "#         mas = RobustScaler()\n",
    "#         rescaled_data = mas.fit_transform(data_points)        \n",
    "        KM = KMeans(n_clusters=2)\n",
    "        labels = KM.fit_predict(rescaled_data)\n",
    "        \n",
    "        self.classifier.fit(X, labels) #, **kwargs)\n",
    "        \n",
    "        return labels\n",
    "\n",
    "    def restart(self):\n",
    "        X_init = latin_hypercube(self.turbo.n_init, self.dim)\n",
    "        \n",
    "        if self.initiated is False: # when initiating\n",
    "            self.X_init = from_unit_cube(X_init, self.lb, self.ub)\n",
    "        else: # if it is restarting, initiate turbo within selected region\n",
    "            X_init = from_unit_cube(X_init, self.lb, self.ub)\n",
    "            _ = self.train_classifier(deepcopy(self.turbo._X),deepcopy(self.turbo._fX))\n",
    "            self.selected_label = self.classifier.predict(self.turbo._X[self.turbo._fX.argmin().item()][None,:]) \n",
    "            y_pred = self.classifier.predict(X_init)\n",
    "            self.X_init = X_init[np.where(y_pred==self.selected_label)]\n",
    "            \n",
    "        self.turbo._restart() # reset succ&fail count, length\n",
    "        self.turbo._X = np.zeros((0, self.turbo.dim))\n",
    "        self.turbo._fX = np.zeros((0, 1))\n",
    "        self.epoch = 0\n",
    "\n",
    "    def make_type_list(self):\n",
    "        int_where_type = [False] * len(self.api_config)\n",
    "        bool_where_type = [False] * len(self.api_config)\n",
    "        float_where_type = [False] * len(self.api_config)\n",
    "        cat_where_type = [False] * len(self.api_config)\n",
    "        for ind, param in enumerate(self.api_config):\n",
    "            if self.api_config[param]['type'] == 'int':\n",
    "                int_where_type[ind] = True\n",
    "            elif self.api_config[param]['type'] == 'real':\n",
    "                float_where_type[ind] = True\n",
    "            elif self.api_config[param]['type'] == 'bool':\n",
    "                bool_where_type[ind] = True\n",
    "            elif self.api_config[param]['type'] == 'cat':\n",
    "                cat_where_type[ind] = True\n",
    "        \n",
    "        return int_where_type, bool_where_type, float_where_type, cat_where_type\n",
    "            \n",
    "        \n",
    "    def find_loc(self):\n",
    "        # data_type = np.float64 # np.float64 # np.unicode_\n",
    "        # space: int - np.int_, float: np.float_, bool: np.bool_, cat: np.unicode_\n",
    "        int_where_type, bool_where_type, float_where_type, cat_where_type = self.make_type_list()\n",
    "\n",
    "        len_each_bounds = np.array([len(self.space_x.spaces[param].get_bounds()) for param in self.space_x.param_list])\n",
    "        blocks = self.space_x.blocks\n",
    "\n",
    "        int_where_end = blocks[np.where(int_where_type)]\n",
    "        bool_where_end = blocks[np.where(bool_where_type)]\n",
    "        float_where_end = blocks[np.where(float_where_type)]\n",
    "        cat_where_end = blocks[np.where(cat_where_type)]\n",
    "        \n",
    "        int_where_bound = len_each_bounds[np.where(int_where_type)]\n",
    "        bool_where_bound = len_each_bounds[np.where(bool_where_type)]\n",
    "        float_where_bound = len_each_bounds[np.where(float_where_type)]\n",
    "        cat_where_bound = len_each_bounds[np.where(cat_where_type)]\n",
    "\n",
    "        int_intervals = [(int_where_end[idx]- int_where_bound[idx] ,int_where_end[idx]) for idx in range(len(int_where_end))]\n",
    "        bool_intervals = [(bool_where_end[idx]- bool_where_bound[idx] , bool_where_end[idx]) for idx in range(len(bool_where_end))]\n",
    "        float_intervals = [(float_where_end[idx]- float_where_bound[idx] , float_where_end[idx]) for idx in range(len(float_where_end))]\n",
    "        cat_intervals = [(cat_where_end[idx]- cat_where_bound[idx] ,cat_where_end[idx]) for idx in range(len(cat_where_end))]\n",
    "            \n",
    "        int_dim = []\n",
    "        bool_dim = []\n",
    "        float_dim = []\n",
    "        cat_dim = []\n",
    "\n",
    "        # int interval\n",
    "        if int_intervals:\n",
    "            for (s, e) in int_intervals:\n",
    "                for idx in range(s,e):\n",
    "                    int_dim.append(idx)\n",
    "        # bool_interval\n",
    "        if bool_intervals:\n",
    "            for (s, e) in bool_intervals:\n",
    "                for idx in range(s,e):\n",
    "                    bool_dim.append(idx)       \n",
    "        # float_interval\n",
    "        if float_intervals:\n",
    "            for (s, e) in float_intervals:\n",
    "                for idx in range(s,e):\n",
    "                    float_dim.append(idx)\n",
    "        # cat_interval\n",
    "        if cat_intervals:\n",
    "            for (s, e) in cat_intervals:\n",
    "                for idx in range(s,e):\n",
    "                    cat_dim.append(idx)          \n",
    "\n",
    "        cat_where_loc = [-1]*max(blocks) # since block is built up by cumsum, max value considers num of cat values\n",
    "        for location in cat_dim:\n",
    "            cat_where_loc[location] = 0\n",
    "            \n",
    "        return int_dim, bool_dim, float_dim, cat_dim, cat_where_loc\n",
    "\n",
    "    \n",
    "    def initialize_mab(self):\n",
    "        params = {}\n",
    "        if 'int' in self._mab_var:\n",
    "            for dim in self.int_dim:\n",
    "                gt_lb = self.space_x.unwarp(self.lb[None,:])[0][self.space_x.param_list[self.return_true_dim[dim]]]\n",
    "                gt_ub = self.space_x.unwarp(self.ub[None,:])[0][self.space_x.param_list[self.return_true_dim[dim]]]\n",
    "                if gt_ub-gt_lb < 11:\n",
    "                    params[dim] = {}\n",
    "                    for num in range(int(gt_lb), int(gt_ub+1)):\n",
    "                        params[dim][num] = {'alpha': 1., 'beta': 1.}\n",
    "                    \n",
    "        if 'bool' in self._mab_var:\n",
    "            for dim in self.bool_dim:\n",
    "                params[dim] = {}\n",
    "                for num in range(int(self.lb[dim]), int(self.ub[dim]+1)):\n",
    "                    params[dim][num] = {'alpha': 1., 'beta': 1.}\n",
    "                    \n",
    "        if 'cat' in self._mab_var:\n",
    "            if 0 in np.unique(self.cat_loc):\n",
    "                params['cat'] = {}\n",
    "            for dim in np.unique(self.cat_loc):\n",
    "                if dim != -1:\n",
    "                    params['cat'][dim]={}                \n",
    "                    for cor_dim in np.where(self.cat_loc==dim)[0]:\n",
    "                        params['cat'][dim][cor_dim] = {'alpha': 1., 'beta': 1.}\n",
    "        \n",
    "        return params\n",
    "    \n",
    "    def sample_mab(self):\n",
    "        result = {}\n",
    "        if self.params:\n",
    "            for dim_key in self.params.keys():\n",
    "                if dim_key != 'cat':\n",
    "                    best = - 1.\n",
    "                    for can_key in self.params[dim_key].keys():\n",
    "                        tmp = np.random.beta(self.params[dim_key][can_key]['alpha'], self.params[dim_key][can_key]['beta'])\n",
    "                        if tmp > best:\n",
    "                            best = tmp\n",
    "                            best_cand = self.space_x.spaces[self.space_x.param_list[self.return_true_dim[dim_key]]].warp(can_key)\n",
    "                    result[dim_key] = best_cand\n",
    "                else:\n",
    "                    for cat_key in self.params['cat'].keys():\n",
    "                        tmp_list = []\n",
    "                        for can_key in self.params['cat'][cat_key].keys():\n",
    "                            tmp = np.random.beta(self.params['cat'][cat_key][can_key]['alpha'], self.params['cat'][cat_key][can_key]['beta'])\n",
    "                            tmp_list.append(tmp)\n",
    "                        argmax_list = [1. if idx == np.argmax(tmp_list) else 0. for idx in range(len(tmp_list))]\n",
    "                        for idx, can_key in enumerate(self.params['cat'][cat_key].keys()):\n",
    "                            result[can_key] = argmax_list[idx]\n",
    "        return result\n",
    "    \n",
    "    def update_mab(self, XX, fX_next, random=False):\n",
    "        for index in range(len(fX_next)):\n",
    "            if random:\n",
    "                if round(fX_next[index][0],4) < round(np.min(fX_next),4) + 1e-5:\n",
    "                    if self.params:\n",
    "                        for key in self.params.keys():\n",
    "                            if key != 'cat':\n",
    "                                if key in self.int_dim:\n",
    "                                    unwarped_X = self.space_x.unwarp(XX[index][None,:])[0][self.space_x.param_list[self.return_true_dim[key]]]\n",
    "                                    self.params[key][unwarped_X]['alpha'] += 3. \n",
    "                                    if unwarped_X + 1 in self.params[key].keys():\n",
    "                                        self.params[key][unwarped_X + 1]['alpha'] += 1.\n",
    "                                    if unwarped_X - 1 in self.params[key].keys():\n",
    "                                        self.params[key][unwarped_X - 1]['alpha'] += 1.\n",
    "                                    if unwarped_X + 2 in self.params[key].keys():\n",
    "                                        self.params[key][unwarped_X + 2]['alpha'] += 0.5\n",
    "                                    if unwarped_X - 2 in self.params[key].keys():\n",
    "                                        self.params[key][unwarped_X - 2]['alpha'] += 0.5\n",
    "                                else:\n",
    "                                    self.params[key][XX[index][key]]['alpha'] += 1.5\n",
    "                            else:\n",
    "                                for cat_key in self.params['cat'].keys():\n",
    "                                    for can_key in self.params['cat'][cat_key].keys():\n",
    "                                        self.params['cat'][cat_key][can_key]['alpha'] += XX[index][can_key] * 1.5\n",
    "            elif fX_next[index][0] < np.min(self.turbo._fX) - 1e-5 * math.fabs(np.min(self.turbo._fX)):\n",
    "                if self.params:\n",
    "                    for key in self.params.keys():\n",
    "                        if key != 'cat':\n",
    "                            if key in self.int_dim:\n",
    "                                unwarped_X = self.space_x.unwarp(XX[index][None,:])[0][self.space_x.param_list[self.return_true_dim[key]]]\n",
    "                                self.params[key][unwarped_X]['alpha'] += 2.5 #max(2.5, len(self.params[key].keys()) / self.batch_size)\n",
    "                                if unwarped_X + 1 in self.params[key].keys():\n",
    "                                    self.params[key][unwarped_X + 1]['alpha'] += 1.5\n",
    "                                if unwarped_X - 1 in self.params[key].keys():\n",
    "                                    self.params[key][unwarped_X - 1]['alpha'] += 1.\n",
    "                                if unwarped_X + 2 in self.params[key].keys():\n",
    "                                    self.params[key][unwarped_X + 2]['alpha'] += 0.5\n",
    "                                if unwarped_X - 2 in self.params[key].keys():\n",
    "                                    self.params[key][unwarped_X - 2]['alpha'] += 0.5\n",
    "                            else:\n",
    "                                self.params[key][XX[index][key]]['alpha'] += 1.5\n",
    "                        else:\n",
    "                            for cat_key in self.params['cat'].keys():\n",
    "                                for can_key in self.params['cat'][cat_key].keys():\n",
    "                                    self.params['cat'][cat_key][can_key]['alpha'] += XX[index][can_key] * 1.5\n",
    "\n",
    "#             else:\n",
    "#                 for key in self.params.keys():\n",
    "#                     self.params[key][XX[index][key]]['beta'] += 1 / 8\n",
    "        \n",
    "    def discount_mab(self):\n",
    "        # discount other params\n",
    "        _discount = self._discount\n",
    "        for dim_key in self.params.keys():\n",
    "            if dim_key != 'cat':\n",
    "                for can_key in self.params[dim_key].keys():\n",
    "                    self.params[dim_key][can_key]['alpha'] *= _discount\n",
    "                    self.params[dim_key][can_key]['beta'] *= _discount\n",
    "            else:\n",
    "                catparam = self.params['cat']\n",
    "                for can_key in catparam.keys():\n",
    "                    for val_key in catparam[can_key].keys():\n",
    "                        catparam[can_key][val_key]['alpha'] *= _discount\n",
    "                        catparam[can_key][val_key]['beta'] *= _discount\n",
    "                \n",
    "    def subsample_mab(self, X_cand):\n",
    "        X_cand_tmp = from_unit_cube(X_cand,self.lb,self.ub)\n",
    "        for index in range(len(X_cand)):\n",
    "            tmp = self.sample_mab()\n",
    "            if tmp:\n",
    "                for key in tmp.keys():\n",
    "                    X_cand[index][key] = float((tmp[key]-self.lb[key])/(self.ub[key]-self.lb[key]))\n",
    " \n",
    "        return X_cand\n",
    "\n",
    "    def suggest(self, n_suggestions=10):\n",
    "        if self.batch_size is None:  # Remember the batch size on the first call to suggest\n",
    "            self.batch_size = n_suggestions\n",
    "            self.turbo.batch_size = n_suggestions\n",
    "            self.turbo.failtol = np.ceil(np.max([4.0 / self.batch_size, self.dim / self.batch_size]))\n",
    "            self.turbo.n_init = max([self.turbo.n_init, self.batch_size])\n",
    "            self.restart()\n",
    "\n",
    "        X_next = np.zeros((n_suggestions, self.dim))\n",
    "\n",
    "        # Pick from the initial points\n",
    "        n_init = min(len(self.X_init), n_suggestions)\n",
    "        if n_init > 0:\n",
    "            X_next[:n_init] = deepcopy(self.X_init[:n_init, :])\n",
    "            self.X_init = self.X_init[n_init:, :]  # Remove these pending points\n",
    "            self.initiated = True\n",
    "\n",
    "        # Get remaining points from TuRBO\n",
    "        n_adapt = n_suggestions - n_init\n",
    "        if n_adapt > 0 and self.initiated is True and len(self.turbo._X) > 0: ## n_suggestion 1\n",
    "            kmeans_labels = self.train_classifier(deepcopy(self.turbo._X),deepcopy(self.turbo._fX))\n",
    "        \n",
    "        if n_adapt > 0:\n",
    "            if len(self.turbo._X) > 0:  # Use random points if we can't fit a GP\n",
    "                if self.adapt_region == 'ucb':\n",
    "                    self.selected_label = self.select_region_by_ucb(deepcopy(self.turbo.fX),labels)\n",
    "                else:\n",
    "                    input_labels = self.classifier.predict(deepcopy(self.turbo._X))\n",
    "                    self.selected_label = input_labels[self.turbo._fX.argmin().item()]\n",
    "                \n",
    "                x_select = deepcopy(self.turbo._X)[np.where(input_labels==self.selected_label)]\n",
    "                y_select = deepcopy(self.turbo._fX)[np.where(input_labels==self.selected_label)]\n",
    "                \n",
    "                # create TR with the center point inside the selected region\n",
    "                X = to_unit_cube(x_select, self.lb, self.ub)\n",
    "                fX = copula_standardize(y_select.ravel())  # Use Copula\n",
    "                \n",
    "                ## update on 10.04: below code does not solved the suggest exception error on leaderboard\n",
    "                ## though the exception appears occasionally\n",
    "                ## so i guess this is not the case.. but i'll just leave it as it is \n",
    "                sel_y_cand = np.array([])\n",
    "                timeout = 2\n",
    "                time_started = time.time()\n",
    "                while len(sel_y_cand) < n_adapt and time.time()<time_started+timeout:\n",
    "                    X_cand, _ = self.turbo._create_candidates(\n",
    "                        X, fX, length=self.turbo.length, n_training_steps=80, hypers={}, epoch = self.epoch, int_dim = self.int_dim, bool_dim = self.bool_dim, float_dim = self.float_dim, cat_dim = self.cat_dim\n",
    "                    )\n",
    "                    X_cand = self.subsample_mab(X_cand)\n",
    "                    y_cand = self.turbo.generate_ycand(X_cand)\n",
    "\n",
    "                    # reject that are out of range using classifier\n",
    "                    label_X_cand = self.classifier.predict(from_unit_cube(X_cand,self.lb,self.ub))\n",
    "\n",
    "                    sel_X_cand = X_cand[np.where(label_X_cand==self.selected_label)]\n",
    "                    sel_y_cand = y_cand[np.where(label_X_cand==self.selected_label)]\n",
    "                # also select the candidates from the selected region\n",
    "                if len(sel_y_cand) >= n_adapt:\n",
    "                    X_next[-n_adapt:, :] = self.turbo._select_candidates(sel_X_cand, sel_y_cand)[:n_adapt, :]               \n",
    "                else:\n",
    "                    X_next[-n_adapt:, :] = self.turbo._select_candidates(X_cand, y_cand)[:n_adapt, :]\n",
    "                X_next[-n_adapt:, :] = from_unit_cube(X_next[-n_adapt:, :], self.lb, self.ub)\n",
    "            else:\n",
    "                # code below is for the case\n",
    "                # when restarted, but num of X_init that satisfies the classifier is smaller than n_suggestion \n",
    "                # create more samples \n",
    "                \n",
    "#                 print(\"iterating for extra samples..\")\n",
    "                timeout = 1\n",
    "                time_started = time.time()\n",
    "                while True and time.time()<time_started+timeout:\n",
    "                    X_init = latin_hypercube(self.turbo.n_init, self.dim)\n",
    "                    X_init = from_unit_cube(X_init, self.lb, self.ub)\n",
    "                    y_pred = self.classifier.predict(X_init)\n",
    "                    extra_X_init = X_init[np.where(y_pred==self.selected_label)]\n",
    "                    if len(extra_X_init) < n_adapt:\n",
    "                        continue\n",
    "                    else:\n",
    "                        X_next[-n_adapt:, :] = deepcopy(extra_X_init[:n_adapt, :])\n",
    "                        break\n",
    "                else: \n",
    "                    # create additional samples (random, do not fit in the satisfaction)\n",
    "                    extra_X = latin_hypercube(self.turbo.n_init, self.dim)\n",
    "                    extra_X = from_unit_cube(extra_X, self.lb, self.ub)\n",
    "                    X_next[-n_adapt:, :] = extra_X[:n_adapt, :]\n",
    "\n",
    "        # Unwarp the suggestions\n",
    "        suggestions = self.space_x.unwarp(X_next)\n",
    "        self.epoch += 1\n",
    "        \n",
    "        return suggestions\n",
    "\n",
    "    def observe(self, X, y):\n",
    "        \"\"\"Send an observation of a suggestion back to the optimizer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : list of dict-like\n",
    "            Places where the objective function has already been evaluated.\n",
    "            Each suggestion is a dictionary where each key corresponds to a\n",
    "            parameter being optimized.\n",
    "        y : array-like, shape (n,)\n",
    "            Corresponding values where objective has been evaluated\n",
    "        \"\"\"\n",
    "        assert len(X) == len(y)\n",
    "        \n",
    "        XX, yy = self.space_x.warp(X), np.array(y)[:, None]\n",
    "        \n",
    "#         print('int', self.int_dim, 'bool', self.bool_dim, 'float', self.float_dim, 'length', self.turbo.length)\n",
    "        if len(self.turbo._fX) < self.turbo.n_init:\n",
    "            self.update_mab(XX, yy, random=True)\n",
    "\n",
    "        if len(self.turbo._fX) >= self.turbo.n_init:\n",
    "            self.update_mab(XX, yy)\n",
    "            self.turbo._adjust_length(yy, self.span, self.squeeze)\n",
    "\n",
    "        self.turbo.n_evals += self.batch_size\n",
    "\n",
    "        self.turbo._X = np.vstack((self.turbo._X, deepcopy(XX)))\n",
    "        self.turbo._fX = np.vstack((self.turbo._fX, deepcopy(yy)))\n",
    "        self.turbo.X = np.vstack((self.turbo.X, deepcopy(XX)))\n",
    "        self.turbo.fX = np.vstack((self.turbo.fX, deepcopy(yy)))\n",
    "\n",
    "        # Check for a restart\n",
    "#         if self.turbo.volume < self.turbo.vol_min:# and self.flag:\n",
    "#             self.restart()\n",
    "        if self.turbo.length < self.turbo.length_min:\n",
    "            self.restart()\n",
    "            print(\"restart\")\n",
    "            \n",
    "    def get_fX(self, x, f):\n",
    "        \"\"\"\n",
    "        x : Unwarped suggestion\n",
    "        f : Function to optimize\n",
    "        \"\"\"\n",
    "        XX = self.space_x.warp(x)\n",
    "        y = np.array([[f(X)] for X in XX])\n",
    "        if y.ndim > 1 :\n",
    "            y =  y.reshape(-1)\n",
    "        return y\n",
    "    \n",
    "    def optimize(self, f, num_evals=10, n_suggestions=10): # Suggest + Observe\n",
    "        \n",
    "        min_yy = float(\"inf\")\n",
    "        for e in range(num_evals):\n",
    "            suggestions = self.suggest(n_suggestions=n_suggestions)\n",
    "            yy = self.get_fX(suggestions, f)\n",
    "            self.observe(suggestions, yy)\n",
    "            if yy.min() < min_yy :\n",
    "                min_yy = yy.min()\n",
    "                print(\"Evaluation iter : {}, yy minimum : {}\".format(e, yy.min()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Levy:\n",
    "    def __init__(self, dim=10):\n",
    "        self.dim = dim\n",
    "        self.lb = -5 * np.ones(dim)\n",
    "        self.ub = 10 * np.ones(dim)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        assert len(x) == self.dim\n",
    "        assert x.ndim == 1\n",
    "        assert np.all(x <= self.ub) and np.all(x >= self.lb)\n",
    "        w = 1 + (x - 1.0) / 4.0\n",
    "        val = np.sin(np.pi * w[0]) ** 2 + \\\n",
    "            np.sum((w[1:self.dim - 1] - 1) ** 2 * (1 + 10 * np.sin(np.pi * w[1:self.dim - 1] + 1) ** 2)) + \\\n",
    "            (w[self.dim - 1] - 1) ** 2 * (1 + np.sin(2 * np.pi * w[self.dim - 1])**2)\n",
    "        return val\n",
    "\n",
    "\n",
    "class Ackley:\n",
    "    def __init__(self, dims=10):\n",
    "        self.dims      = dims\n",
    "        self.lb        = -5 * np.ones(dims)\n",
    "        self.ub        =  10 * np.ones(dims)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        assert len(x) == self.dims\n",
    "        assert x.ndim == 1\n",
    "        assert np.all(x <= self.ub) and np.all(x >= self.lb)\n",
    "        result = (-20*np.exp(-0.2 * np.sqrt(np.inner(x,x) / x.size )) -np.exp(np.cos(2*np.pi*x).sum() /x.size) + 20 +np.e )\n",
    "                \n",
    "        return result\n",
    "    \n",
    "def print_avg(results):\n",
    "    print(\"Albo Levy average  :{}, Ackley : {}\".format(np.average(results['levy']), np.average(results['ackley'])) )\n",
    "    print(\"Albo Levy STD  :{}, Ackley : {}\".format(np.std(results['levy']), np.std(results['ackley'])) )\n",
    "    \n",
    "    \n",
    "def save_plot(fX, func):\n",
    "    fX = AT.turbo.fX\n",
    "    matplotlib.rcParams.update({'font.size': 16})\n",
    "    plt.plot(fX, 'b.', ms=10)  # Plot all evaluated points as blue dots\n",
    "    plt.plot(np.minimum.accumulate(fX), 'r', lw=3)  # Plot cumulative minimum as a red line\n",
    "    plt.xlim([0, len(fX)])\n",
    "    plt.ylim([0, 30])\n",
    "    plt.title(\"10D {} function\".format(func))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(\"svm_local_0.45.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Runs for Levy, Ackley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Seed :  0\n",
      "Evaluation iter : 0, yy minimum : 16.784189478683658\n",
      "Evaluation iter : 6, yy minimum : 14.240561918396814\n",
      "Evaluation iter : 7, yy minimum : 11.513369835149224\n",
      "Evaluation iter : 8, yy minimum : 9.644686717561497\n",
      "Evaluation iter : 10, yy minimum : 8.89345650732048\n",
      "Evaluation iter : 14, yy minimum : 8.716523362174359\n",
      "Evaluation iter : 15, yy minimum : 8.590948307938104\n",
      "Evaluation iter : 16, yy minimum : 8.495366297283134\n",
      "Evaluation iter : 17, yy minimum : 8.396436893388751\n",
      "Evaluation iter : 18, yy minimum : 8.210668952880136\n",
      "Evaluation iter : 19, yy minimum : 8.06898094717489\n",
      "Evaluation iter : 21, yy minimum : 7.955799296221575\n",
      "Evaluation iter : 22, yy minimum : 7.893337499910155\n",
      "Evaluation iter : 24, yy minimum : 7.833035565621137\n",
      "restart\n",
      "Evaluation iter : 33, yy minimum : 7.440650739973238\n",
      "Evaluation iter : 35, yy minimum : 6.4761273096741165\n",
      "Evaluation iter : 36, yy minimum : 2.4871552157575207\n",
      "Evaluation iter : 38, yy minimum : 2.315632882965557\n",
      "Evaluation iter : 39, yy minimum : 2.122310432829444\n",
      "Evaluation iter : 40, yy minimum : 1.9279253339428613\n",
      "Evaluation iter : 42, yy minimum : 1.3572465359742372\n",
      "Evaluation iter : 43, yy minimum : 1.1041268573382463\n",
      "Evaluation iter : 46, yy minimum : 1.060648383796551\n",
      "Evaluation iter : 47, yy minimum : 1.0420378347752242\n",
      "Evaluation iter : 48, yy minimum : 1.015133947895693\n",
      "Evaluation iter : 49, yy minimum : 0.949626207976897\n",
      "Evaluation iter : 51, yy minimum : 0.9288677301513013\n",
      "Evaluation iter : 53, yy minimum : 0.9244379049057856\n",
      "Evaluation iter : 54, yy minimum : 0.918755745370781\n",
      "Evaluation iter : 56, yy minimum : 0.9182456874355678\n",
      "restart\n",
      "Evaluation iter : 74, yy minimum : 0.8745990033755119\n",
      "Evaluation iter : 76, yy minimum : 0.7721922751054827\n",
      "Evaluation iter : 78, yy minimum : 0.7392121515263794\n",
      "Evaluation iter : 79, yy minimum : 0.6779953414165447\n",
      "Evaluation iter : 80, yy minimum : 0.6053575434229042\n",
      "Evaluation iter : 82, yy minimum : 0.5106541827733875\n",
      "Evaluation iter : 85, yy minimum : 0.4882062358646166\n",
      "Evaluation iter : 86, yy minimum : 0.4881941485594692\n",
      "Evaluation iter : 87, yy minimum : 0.47761034477963005\n",
      "Evaluation iter : 89, yy minimum : 0.4693685639424588\n",
      "Evaluation iter : 91, yy minimum : 0.46764844299478286\n",
      "Evaluation iter : 92, yy minimum : 0.4637285164472055\n",
      "Evaluation iter : 93, yy minimum : 0.4611158188272685\n",
      "Evaluation iter : 94, yy minimum : 0.46101080155539675\n",
      "Evaluation iter : 95, yy minimum : 0.45853948193921407\n",
      "restart\n",
      "====================\n",
      "Seed :  1\n",
      "Evaluation iter : 0, yy minimum : 16.41905705243541\n",
      "Evaluation iter : 3, yy minimum : 12.3966473186728\n",
      "Evaluation iter : 4, yy minimum : 8.124629489921116\n",
      "Evaluation iter : 6, yy minimum : 2.715339868305812\n",
      "Evaluation iter : 8, yy minimum : 2.480575482666601\n",
      "Evaluation iter : 9, yy minimum : 2.3816611697822174\n",
      "Evaluation iter : 10, yy minimum : 2.067308050686861\n",
      "Evaluation iter : 11, yy minimum : 1.3779190133267383\n",
      "Evaluation iter : 14, yy minimum : 0.9162669147080381\n",
      "Evaluation iter : 15, yy minimum : 0.5418905200353545\n",
      "Evaluation iter : 16, yy minimum : 0.5386787784431806\n",
      "Evaluation iter : 18, yy minimum : 0.29354499671084266\n",
      "Evaluation iter : 20, yy minimum : 0.17018877215548325\n",
      "Evaluation iter : 21, yy minimum : 0.10137807028025063\n",
      "Evaluation iter : 23, yy minimum : 0.08031431944592445\n",
      "Evaluation iter : 24, yy minimum : 0.07953576695199005\n",
      "Evaluation iter : 26, yy minimum : 0.07065650576513917\n",
      "Evaluation iter : 27, yy minimum : 0.05238184949163574\n",
      "Evaluation iter : 28, yy minimum : 0.03642501827850682\n",
      "Evaluation iter : 30, yy minimum : 0.013882419202944496\n",
      "Evaluation iter : 31, yy minimum : 0.00773739314960741\n",
      "Evaluation iter : 33, yy minimum : 0.006983174898270574\n",
      "Evaluation iter : 34, yy minimum : 0.005229332994276314\n",
      "restart\n",
      "restart\n",
      "====================\n",
      "Seed :  2\n",
      "Evaluation iter : 0, yy minimum : 25.022813493503467\n",
      "Evaluation iter : 2, yy minimum : 24.12353556151394\n",
      "Evaluation iter : 4, yy minimum : 10.934385764907455\n",
      "Evaluation iter : 6, yy minimum : 10.093127002407176\n",
      "Evaluation iter : 7, yy minimum : 6.576143080867714\n",
      "Evaluation iter : 8, yy minimum : 4.781997212293178\n",
      "Evaluation iter : 9, yy minimum : 3.6932392330342263\n",
      "Evaluation iter : 10, yy minimum : 1.8480299375419245\n",
      "Evaluation iter : 12, yy minimum : 1.5284535005542563\n",
      "Evaluation iter : 14, yy minimum : 0.974767110925389\n",
      "Evaluation iter : 16, yy minimum : 0.7577965680246738\n",
      "Evaluation iter : 17, yy minimum : 0.7460408941293193\n",
      "Evaluation iter : 19, yy minimum : 0.7123377006162287\n",
      "Evaluation iter : 20, yy minimum : 0.7089749136710568\n",
      "Evaluation iter : 21, yy minimum : 0.6684535372881478\n",
      "Evaluation iter : 22, yy minimum : 0.6512448146410679\n",
      "Evaluation iter : 23, yy minimum : 0.5651411280079761\n",
      "Evaluation iter : 24, yy minimum : 0.5500637135221448\n",
      "Evaluation iter : 26, yy minimum : 0.5094163957411821\n",
      "Evaluation iter : 28, yy minimum : 0.46815025339862715\n",
      "Evaluation iter : 31, yy minimum : 0.46126678051548076\n",
      "restart\n",
      "restart\n",
      "restart\n",
      "====================\n",
      "Seed :  3\n",
      "Evaluation iter : 0, yy minimum : 23.859768843548526\n",
      "Evaluation iter : 4, yy minimum : 19.414631025566027\n",
      "Evaluation iter : 6, yy minimum : 18.133057063064605\n",
      "Evaluation iter : 8, yy minimum : 17.861744032045127\n",
      "Evaluation iter : 9, yy minimum : 16.447481648549342\n",
      "Evaluation iter : 11, yy minimum : 13.730540280916586\n",
      "Evaluation iter : 12, yy minimum : 12.864826913833975\n",
      "Evaluation iter : 13, yy minimum : 12.454863084860133\n",
      "Evaluation iter : 15, yy minimum : 12.120527739001794\n",
      "Evaluation iter : 16, yy minimum : 11.636096906986573\n",
      "Evaluation iter : 18, yy minimum : 11.611722033562655\n",
      "Evaluation iter : 19, yy minimum : 11.574822559141843\n",
      "Evaluation iter : 20, yy minimum : 11.500541348188786\n",
      "Evaluation iter : 22, yy minimum : 11.490390841216012\n",
      "Evaluation iter : 24, yy minimum : 11.410988518031449\n",
      "Evaluation iter : 25, yy minimum : 11.368153772476917\n",
      "Evaluation iter : 26, yy minimum : 11.366283899644749\n",
      "Evaluation iter : 29, yy minimum : 11.36102627921953\n",
      "Evaluation iter : 30, yy minimum : 11.350992263377183\n",
      "restart\n",
      "Evaluation iter : 37, yy minimum : 9.63767948120339\n",
      "Evaluation iter : 38, yy minimum : 5.600445683124604\n",
      "Evaluation iter : 40, yy minimum : 3.376433260958566\n",
      "Evaluation iter : 41, yy minimum : 2.1613666350205687\n",
      "Evaluation iter : 42, yy minimum : 2.0957535852450504\n",
      "Evaluation iter : 45, yy minimum : 1.9657616602082426\n",
      "Evaluation iter : 47, yy minimum : 1.2744775461749347\n",
      "Evaluation iter : 48, yy minimum : 1.1488467223653995\n",
      "Evaluation iter : 50, yy minimum : 1.0703340275687152\n",
      "Evaluation iter : 51, yy minimum : 1.0613272620528886\n",
      "Evaluation iter : 52, yy minimum : 1.0315174830872171\n",
      "Evaluation iter : 54, yy minimum : 1.0308602577697\n",
      "Evaluation iter : 55, yy minimum : 1.0277072598522499\n",
      "Evaluation iter : 56, yy minimum : 0.9807193410213902\n",
      "Evaluation iter : 58, yy minimum : 0.9535402973217404\n",
      "Evaluation iter : 60, yy minimum : 0.9409020490721453\n",
      "Evaluation iter : 61, yy minimum : 0.9255886261671562\n",
      "Evaluation iter : 63, yy minimum : 0.916488254246736\n",
      "restart\n",
      "restart\n",
      "====================\n",
      "Seed :  4\n",
      "Evaluation iter : 0, yy minimum : 11.51883818818629\n",
      "Evaluation iter : 6, yy minimum : 10.881789882764469\n",
      "Evaluation iter : 7, yy minimum : 10.39344803408405\n",
      "Evaluation iter : 8, yy minimum : 8.0051568479785\n",
      "Evaluation iter : 9, yy minimum : 7.118921856280828\n",
      "Evaluation iter : 11, yy minimum : 5.626104314189621\n",
      "Evaluation iter : 12, yy minimum : 5.12626967605341\n",
      "Evaluation iter : 14, yy minimum : 5.058014779679404\n",
      "Evaluation iter : 15, yy minimum : 4.879955068812189\n",
      "Evaluation iter : 16, yy minimum : 4.619305815573943\n",
      "Evaluation iter : 17, yy minimum : 4.543151744311051\n",
      "Evaluation iter : 18, yy minimum : 4.383741313266549\n",
      "Evaluation iter : 19, yy minimum : 4.0843396389600155\n",
      "Evaluation iter : 21, yy minimum : 4.012968380669601\n",
      "Evaluation iter : 23, yy minimum : 3.9848305744693215\n",
      "Evaluation iter : 26, yy minimum : 3.960598322440323\n",
      "Evaluation iter : 27, yy minimum : 3.9255861945025767\n",
      "Evaluation iter : 28, yy minimum : 3.918616965612236\n",
      "Evaluation iter : 30, yy minimum : 3.889477753834649\n",
      "Evaluation iter : 31, yy minimum : 3.858021353130266\n",
      "Evaluation iter : 32, yy minimum : 3.835039097420972\n",
      "Evaluation iter : 33, yy minimum : 3.8107018789542213\n",
      "Evaluation iter : 34, yy minimum : 3.803839034154733\n",
      "Evaluation iter : 36, yy minimum : 3.7594461362325506\n",
      "Evaluation iter : 37, yy minimum : 3.75160813777208\n",
      "restart\n",
      "Evaluation iter : 39, yy minimum : 3.7515878768907602\n",
      "Evaluation iter : 49, yy minimum : 2.3638118687744587\n",
      "Evaluation iter : 51, yy minimum : 1.6941593892271134\n",
      "Evaluation iter : 53, yy minimum : 1.0257075904075743\n",
      "Evaluation iter : 54, yy minimum : 0.668109959640158\n",
      "Evaluation iter : 55, yy minimum : 0.5392604835630236\n",
      "Evaluation iter : 56, yy minimum : 0.45593198247435235\n",
      "Evaluation iter : 58, yy minimum : 0.27438331793536835\n",
      "Evaluation iter : 59, yy minimum : 0.2473010840448496\n",
      "Evaluation iter : 61, yy minimum : 0.1600913933820927\n",
      "Evaluation iter : 63, yy minimum : 0.12348295349257754\n",
      "Evaluation iter : 65, yy minimum : 0.1134871200425698\n",
      "Evaluation iter : 67, yy minimum : 0.1033079580749002\n",
      "Evaluation iter : 68, yy minimum : 0.09835038059671873\n",
      "Evaluation iter : 69, yy minimum : 0.09699568562503856\n",
      "Evaluation iter : 71, yy minimum : 0.09286272963123952\n",
      "Evaluation iter : 72, yy minimum : 0.0920101524512619\n",
      "restart\n",
      "====================\n",
      "Seed :  0\n",
      "Evaluation iter : 0, yy minimum : 12.560071255648149\n",
      "Evaluation iter : 1, yy minimum : 11.116934024306751\n",
      "Evaluation iter : 4, yy minimum : 9.689882301448478\n",
      "Evaluation iter : 6, yy minimum : 9.27457169206375\n",
      "Evaluation iter : 7, yy minimum : 7.475637318183297\n",
      "Evaluation iter : 8, yy minimum : 6.236722143702352\n",
      "Evaluation iter : 9, yy minimum : 6.223210789928544\n",
      "Evaluation iter : 11, yy minimum : 5.1906076058668695\n",
      "Evaluation iter : 12, yy minimum : 4.042230560951889\n",
      "Evaluation iter : 14, yy minimum : 3.1803876392382695\n",
      "Evaluation iter : 16, yy minimum : 3.126127244152667\n",
      "Evaluation iter : 17, yy minimum : 3.074773461961517\n",
      "Evaluation iter : 18, yy minimum : 2.63660492507389\n",
      "Evaluation iter : 19, yy minimum : 2.3867089074722796\n",
      "Evaluation iter : 21, yy minimum : 1.7781196635512662\n",
      "Evaluation iter : 23, yy minimum : 1.4899253518383486\n",
      "Evaluation iter : 25, yy minimum : 1.429684139493983\n",
      "Evaluation iter : 26, yy minimum : 1.2967874260095305\n",
      "restart\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6af502704c29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mAT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdvancedTurbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mAT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_suggestions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Collect Minimum value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-cbfd015755fc>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, f, num_evals, n_suggestions)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0mmin_yy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_evals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0msuggestions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_suggestions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_suggestions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m             \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuggestions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuggestions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-cbfd015755fc>\u001b[0m in \u001b[0;36msuggest\u001b[0;34m(self, n_suggestions)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msel_y_cand\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_adapt\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mtime_started\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                     X_cand, _ = self.turbo._create_candidates(\n\u001b[0;32m--> 408\u001b[0;31m                         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mturbo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_training_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m                     )\n\u001b[1;32m    410\u001b[0m                     \u001b[0mX_cand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubsample_mab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/custom_turbo/turbo/turbo_1.py\u001b[0m in \u001b[0;36m_create_candidates\u001b[0;34m(self, X, fX, length, n_training_steps, hypers, epoch, int_dim, bool_dim, float_dim, cat_dim, option)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0my_torch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             gp = train_gp(\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0mtrain_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_torch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_torch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_ard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_ard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_training_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhypers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             )\n\u001b[1;32m    189\u001b[0m             \u001b[0;31m# Save state dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/custom_turbo/turbo/gp.py\u001b[0m in \u001b[0;36mtrain_gp\u001b[0;34m(train_x, train_y, use_ard, num_steps, int_dim, bool_dim, float_dim, cat_dim, hypers, epoch, batch_size)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/bbo/lib/python3.6/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/bbo/lib/python3.6/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, function_dist, target, *params)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# Get the log prob of the marginal distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# Add additional terms (SGPR / learned inducing points, heteroskedastic likelihood models)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/bbo/lib/python3.6/site-packages/gpytorch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Get log determininat and first part of quadratic form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_quad_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/bbo/lib/python3.6/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36minv_quad_logdet\u001b[0;34m(self, inv_quad_rhs, logdet, reduce_inv_quad)\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mchol_lazy_tensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCholLazyTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m             \u001b[0mcholesky\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCholLazyTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcholesky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_quad_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_inv_quad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_inv_quad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/bbo/lib/python3.6/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36mcholesky\u001b[0;34m(self, upper)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mLazyTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mCholesky\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlower\u001b[0m \u001b[0mtriangular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \"\"\"\n\u001b[0;32m--> 739\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/bbo/lib/python3.6/site-packages/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mcache_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0madd_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/bbo/lib/python3.6/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36m_cholesky\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mkeops_lazy_tensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKeOpsLazyTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mevaluated_kern_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeOpsLazyTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msub_mat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevaluated_kern_mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/bbo/lib/python3.6/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36mevaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    883\u001b[0m         \u001b[0mall\u001b[0m \u001b[0mlazily\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mkernels\u001b[0m \u001b[0mactually\u001b[0m \u001b[0mevaluated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \"\"\"\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minv_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/bbo/lib/python3.6/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36mrepresentation_tree\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0mincluding\u001b[0m \u001b[0mall\u001b[0m \u001b[0msubobjects\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m \u001b[0minternally\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \"\"\"\n\u001b[0;32m-> 1275\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mLazyTensorRepresentationTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/bbo/lib/python3.6/site-packages/gpytorch/lazy/lazy_tensor_representation_tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lazy_tsr)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"representation\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Is it a lazy tensor?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mrepresentation_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepresentation_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrepresentation_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/bbo/lib/python3.6/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36mrepresentation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;31m# representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/bbo/lib/python3.6/site-packages/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mcache_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0madd_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/bbo/lib/python3.6/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36mevaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mtemp_active_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_active_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/bbo/lib/python3.6/site-packages/gpytorch/kernels/kernel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLazyEvaluatedKernelTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/bbo/lib/python3.6/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/bbo/lib/python3.6/site-packages/gpytorch/kernels/scale_kernel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, last_dim_is_batch, diag, **params)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0morig_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_kernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0moutputscales\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/bbo/lib/python3.6/site-packages/gpytorch/kernels/matern_kernel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, diag, **params)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mx1_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlengthscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mx2_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlengthscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovar_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mexp_component\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/bbo/lib/python3.6/site-packages/gpytorch/kernels/kernel.py\u001b[0m in \u001b[0;36mcovar_dist\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, square_dist, dist_postprocess_func, postprocess, **params)\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sq_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1_eq_x2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1_eq_x2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/bbo/lib/python3.6/site-packages/gpytorch/kernels/kernel.py\u001b[0m in \u001b[0;36m_dist\u001b[0;34m(self, x1, x2, postprocess, x1_eq_x2)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1_eq_x2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# TODO: use torch cdist once implementation is improved: https://github.com/pytorch/pytorch/pull/25799\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sq_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1_eq_x2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx1_eq_x2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_min_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_postprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpostprocess\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/bbo/lib/python3.6/site-packages/gpytorch/kernels/kernel.py\u001b[0m in \u001b[0;36m_sq_dist\u001b[0;34m(self, x1, x2, postprocess, x1_eq_x2)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Zero out negative values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_min_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_postprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpostprocess\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "plot_results = {}\n",
    "\n",
    "dimension=10\n",
    "for func in [\"levy\", \"ackley\"]:\n",
    "    if func == \"levy\":\n",
    "        f = Levy(dimension)\n",
    "    else :\n",
    "        f = Ackley(dimension)\n",
    "    \n",
    "    api_config = {}\n",
    "    for i in range(dimension):\n",
    "        api_config[\"dim_\"+str(i)] = {\"type\" : \"real\", \"space\" : \"linear\", \"range\" : (f.lb[0], f.ub[0])}     \n",
    "\n",
    "    min_result = np.zeros(0)\n",
    "    for random_seed in range(5):\n",
    "                \n",
    "        print(\"=\"*20)\n",
    "        print(\"Seed : \", random_seed)\n",
    "        random.seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "       # torch.cuda.manual_seed(random_seed)\n",
    "       # torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "       # torch.backends.cudnn.deterministic = True\n",
    "       # torch.backends.cudnn.benchmark = False\n",
    "\n",
    "        # Optimize\n",
    "        AT = AdvancedTurbo(api_config)\n",
    "        AT.optimize(f, num_evals=100, n_suggestions=10)\n",
    "\n",
    "        # Collect Minimum value\n",
    "        fX = AT.turbo.fX\n",
    "        min_result = np.concatenate((min_result, min(fX)))\n",
    "        plot_results[func+'_'+str(random_seed)] = fX.tolist()\n",
    "        \n",
    "    results[func] = min_result.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_avg(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levy : 0.3129870515672083,  Ackley : 0.12229791434021467\n"
     ]
    }
   ],
   "source": [
    "print(\"Levy : {},  Ackley : {}\".format(np.average(results['levy']) ,np.average(results['ackley'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levy : 0.13984257559162008,  Ackley : 0.12229791434021467\n"
     ]
    }
   ],
   "source": [
    "print(\"Levy : {},  Ackley : {}\".format(np.average(results['levy']) ,np.average(results['ackley'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# fname = \"../results/albo_result_batch10_eval100.json\"\n",
    "# with open(fname, 'w') as f:\n",
    "#     json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname = \"../results/albo_plot_result_batch10_eval100.json\"\n",
    "# with open(fname, 'w') as f:\n",
    "#     json.dump(plot_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Seed :  0\n",
      "Evaluation iter : 0, yy minimum : 16.784189478683658\n",
      "Evaluation iter : 6, yy minimum : 14.240561918396848\n",
      "Evaluation iter : 7, yy minimum : 11.5133698351492\n",
      "Evaluation iter : 8, yy minimum : 9.644686717561536\n",
      "Evaluation iter : 10, yy minimum : 8.893456507320527\n",
      "Evaluation iter : 14, yy minimum : 8.716523362174398\n",
      "Evaluation iter : 15, yy minimum : 8.590948307938152\n",
      "Evaluation iter : 16, yy minimum : 8.495366297283168\n",
      "Evaluation iter : 17, yy minimum : 8.396436893388762\n",
      "Evaluation iter : 18, yy minimum : 8.210668952880141\n",
      "Evaluation iter : 19, yy minimum : 8.068980947174879\n",
      "Evaluation iter : 21, yy minimum : 7.9557992962215325\n",
      "Evaluation iter : 22, yy minimum : 7.893337499910088\n",
      "Evaluation iter : 24, yy minimum : 7.833035565621115\n",
      "restart\n",
      "Evaluation iter : 33, yy minimum : 7.440650739957841\n",
      "Evaluation iter : 35, yy minimum : 6.4761273097297405\n",
      "Evaluation iter : 36, yy minimum : 2.487155215774427\n",
      "Evaluation iter : 38, yy minimum : 2.315632883009547\n",
      "Evaluation iter : 39, yy minimum : 2.1223104329506453\n",
      "Evaluation iter : 40, yy minimum : 1.9279253336840705\n",
      "Evaluation iter : 42, yy minimum : 1.3572465359511263\n",
      "Evaluation iter : 43, yy minimum : 1.1041268573223812\n",
      "Evaluation iter : 46, yy minimum : 1.0606483837886498\n",
      "Evaluation iter : 47, yy minimum : 1.042037834758954\n",
      "Evaluation iter : 48, yy minimum : 1.0151339478928987\n",
      "Evaluation iter : 49, yy minimum : 0.9496262080079876\n",
      "Evaluation iter : 51, yy minimum : 0.9288677301584749\n",
      "Evaluation iter : 53, yy minimum : 0.9244379049198211\n",
      "Evaluation iter : 54, yy minimum : 0.9187557453686814\n",
      "Evaluation iter : 56, yy minimum : 0.9182456874283456\n",
      "restart\n",
      "restart\n",
      "====================\n",
      "Seed :  0\n",
      "Evaluation iter : 0, yy minimum : 12.560071255648149\n",
      "Evaluation iter : 1, yy minimum : 11.116934024306751\n",
      "Evaluation iter : 4, yy minimum : 9.689882301448476\n",
      "Evaluation iter : 6, yy minimum : 9.274571692063745\n",
      "Evaluation iter : 7, yy minimum : 7.4756373181833045\n",
      "Evaluation iter : 8, yy minimum : 6.236722143702291\n",
      "Evaluation iter : 9, yy minimum : 6.223210789928533\n",
      "Evaluation iter : 11, yy minimum : 5.190607605866852\n",
      "Evaluation iter : 12, yy minimum : 4.042230560951925\n",
      "Evaluation iter : 14, yy minimum : 3.180387639238241\n",
      "Evaluation iter : 16, yy minimum : 3.126127244152656\n",
      "Evaluation iter : 17, yy minimum : 3.0747734619614104\n",
      "Evaluation iter : 18, yy minimum : 2.6366049250738937\n",
      "Evaluation iter : 19, yy minimum : 2.386708907472301\n",
      "Evaluation iter : 21, yy minimum : 1.7781196635511667\n",
      "Evaluation iter : 23, yy minimum : 1.4899253518379258\n",
      "Evaluation iter : 25, yy minimum : 1.4296841394938586\n",
      "Evaluation iter : 26, yy minimum : 1.296787426009335\n",
      "restart\n",
      "Evaluation iter : 58, yy minimum : 0.9135527914100234\n",
      "Evaluation iter : 60, yy minimum : 0.737425262963161\n",
      "Evaluation iter : 61, yy minimum : 0.37852216165532626\n",
      "Evaluation iter : 62, yy minimum : 0.34229595402430535\n",
      "Evaluation iter : 64, yy minimum : 0.25653186871814215\n",
      "Evaluation iter : 66, yy minimum : 0.17887422737650427\n",
      "Evaluation iter : 67, yy minimum : 0.1186452560868898\n",
      "Evaluation iter : 68, yy minimum : 0.10925370016114089\n",
      "restart\n"
     ]
    }
   ],
   "source": [
    "plot_results = {}\n",
    "\n",
    "for func in [\"levy\", \"ackley\"]:\n",
    "    if func == \"levy\":\n",
    "        f = Levy(dimension)\n",
    "    else :\n",
    "        f = Ackley(dimension)\n",
    "    \n",
    "    api_config = {}\n",
    "    for i in range(dimension):\n",
    "        api_config[\"dim_\"+str(i)] = {\"type\" : \"real\", \"space\" : \"linear\", \"range\" : (f.lb[0], f.ub[0])}     \n",
    "\n",
    "    min_result = np.zeros(0)\n",
    "    random_seed = 0 \n",
    "    print(\"=\"*20)\n",
    "    print(\"Seed : \", random_seed)\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # Optimize\n",
    "    AT = AdvancedTurbo(api_config)\n",
    "    AT.optimize(f, num_evals=100, n_suggestions=10)\n",
    "\n",
    "    # Collect Minimum value\n",
    "    fX = AT.turbo.fX\n",
    "    min_result = np.concatenate((min_result, min(fX)))\n",
    "    plot_results[func] = fX.tolist()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in [\"levy_0_turbo\", \"ackley_0_turbo\"]:\n",
    "    fX = plot_results[key]\n",
    "    func = key.split('_')[0]\n",
    "    \n",
    "    ylim = 30\n",
    "    if func == 'ackley':\n",
    "        ylim = 15\n",
    "    \n",
    "    matplotlib.rcParams.update({'font.size': 16})\n",
    "    plt.plot(fX, 'b.', ms=10)  # Plot all evaluated points as blue dots\n",
    "    plt.plot(np.minimum.accumulate(fX), 'r', lw=3)  # Plot cumulative minimum as a red line\n",
    "    plt.xlim([0, len(fX)])\n",
    "    plt.ylim([0, ylim])\n",
    "    plt.title(\"10D {} function\".format(func.capitalize()))\n",
    "    \n",
    "    plt.xlabel(\"Number of evaluation\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"../results/3_albo_{}.pdf\".format(func))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  For 200 Dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Seed :  0\n",
      "Evaluation iter : 0, yy minimum : 13.65991419252243\n",
      "Evaluation iter : 22, yy minimum : 13.603401941631128\n",
      "Evaluation iter : 40, yy minimum : 13.461294892954164\n",
      "Evaluation iter : 41, yy minimum : 13.299525248436805\n",
      "Evaluation iter : 42, yy minimum : 13.16255683711756\n",
      "Evaluation iter : 43, yy minimum : 12.997042008660598\n",
      "Evaluation iter : 44, yy minimum : 12.848440034367911\n",
      "Evaluation iter : 45, yy minimum : 12.783706456430988\n",
      "Evaluation iter : 46, yy minimum : 12.658806162928803\n",
      "Evaluation iter : 47, yy minimum : 12.549730070955835\n",
      "Evaluation iter : 48, yy minimum : 12.45344983699754\n",
      "Evaluation iter : 49, yy minimum : 12.360042127014173\n",
      "====================\n",
      "Seed :  1\n",
      "Evaluation iter : 0, yy minimum : 13.449816234773817\n",
      "Evaluation iter : 24, yy minimum : 13.11727968555025\n",
      "Evaluation iter : 40, yy minimum : 13.03024873908506\n",
      "Evaluation iter : 41, yy minimum : 12.867591836375322\n",
      "Evaluation iter : 42, yy minimum : 12.74677743705951\n",
      "Evaluation iter : 43, yy minimum : 12.643617783959442\n",
      "Evaluation iter : 44, yy minimum : 12.466939289274526\n",
      "Evaluation iter : 45, yy minimum : 12.397157524474373\n",
      "Evaluation iter : 46, yy minimum : 12.350928224687955\n",
      "Evaluation iter : 47, yy minimum : 12.1964740768291\n",
      "Evaluation iter : 48, yy minimum : 12.169744611241471\n",
      "Evaluation iter : 49, yy minimum : 12.050954167694655\n",
      "====================\n",
      "Seed :  2\n",
      "Evaluation iter : 0, yy minimum : 14.075249426695537\n",
      "Evaluation iter : 1, yy minimum : 14.02368151062326\n",
      "Evaluation iter : 3, yy minimum : 13.900251251661295\n",
      "Evaluation iter : 5, yy minimum : 13.691607676752565\n",
      "Evaluation iter : 8, yy minimum : 13.687767412405295\n",
      "Evaluation iter : 9, yy minimum : 13.613304387364845\n",
      "Evaluation iter : 33, yy minimum : 13.55504503424121\n",
      "Evaluation iter : 40, yy minimum : 13.376669722980548\n",
      "Evaluation iter : 41, yy minimum : 13.241177896979105\n",
      "Evaluation iter : 42, yy minimum : 13.144885029960566\n",
      "Evaluation iter : 43, yy minimum : 13.008012538207877\n",
      "Evaluation iter : 44, yy minimum : 12.817135187120327\n",
      "Evaluation iter : 45, yy minimum : 12.813406311081307\n",
      "Evaluation iter : 46, yy minimum : 12.67208099527641\n",
      "Evaluation iter : 47, yy minimum : 12.61944280863914\n",
      "Evaluation iter : 48, yy minimum : 12.524742513125247\n",
      "====================\n",
      "Seed :  3\n",
      "Evaluation iter : 0, yy minimum : 13.802904047564958\n",
      "Evaluation iter : 1, yy minimum : 13.76204249812267\n",
      "Evaluation iter : 2, yy minimum : 13.757894670619276\n",
      "Evaluation iter : 5, yy minimum : 13.427180562852174\n",
      "Evaluation iter : 23, yy minimum : 13.391582113072781\n",
      "Evaluation iter : 29, yy minimum : 13.363192833647668\n",
      "Evaluation iter : 40, yy minimum : 13.249561631891753\n",
      "Evaluation iter : 41, yy minimum : 13.067376477439124\n",
      "Evaluation iter : 42, yy minimum : 12.982472276626046\n",
      "Evaluation iter : 43, yy minimum : 12.882447335039082\n",
      "Evaluation iter : 44, yy minimum : 12.71527801716408\n",
      "Evaluation iter : 45, yy minimum : 12.609346851181476\n",
      "Evaluation iter : 46, yy minimum : 12.425842470280374\n",
      "Evaluation iter : 47, yy minimum : 12.423982581069154\n",
      "Evaluation iter : 48, yy minimum : 12.330845110167092\n",
      "Evaluation iter : 49, yy minimum : 12.242296103064641\n",
      "====================\n",
      "Seed :  4\n",
      "Evaluation iter : 0, yy minimum : 14.109501468209876\n",
      "Evaluation iter : 1, yy minimum : 13.94112856329772\n",
      "Evaluation iter : 3, yy minimum : 13.926289905924122\n",
      "Evaluation iter : 4, yy minimum : 13.793441375824498\n",
      "Evaluation iter : 13, yy minimum : 13.650741698985378\n",
      "Evaluation iter : 26, yy minimum : 13.603412957511523\n",
      "Evaluation iter : 32, yy minimum : 13.543781448830464\n",
      "Evaluation iter : 37, yy minimum : 13.508868331404207\n",
      "Evaluation iter : 39, yy minimum : 13.505729808317971\n",
      "Evaluation iter : 40, yy minimum : 13.274140353134209\n",
      "Evaluation iter : 41, yy minimum : 13.216799241405043\n",
      "Evaluation iter : 42, yy minimum : 13.016835190910266\n",
      "Evaluation iter : 43, yy minimum : 12.888279184402524\n",
      "Evaluation iter : 44, yy minimum : 12.80401348161772\n",
      "Evaluation iter : 45, yy minimum : 12.602119754524326\n",
      "Evaluation iter : 46, yy minimum : 12.577250457477628\n",
      "Evaluation iter : 47, yy minimum : 12.366411222503757\n",
      "Evaluation iter : 48, yy minimum : 12.288655444085672\n",
      "Evaluation iter : 49, yy minimum : 12.123032785831745\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "plot_results = {}\n",
    "\n",
    "dimension=200\n",
    "for func in [\"ackley\"]:\n",
    "    if func == \"levy\":\n",
    "        f = Levy(dimension)\n",
    "    else :\n",
    "        f = Ackley(dimension)\n",
    "    \n",
    "    api_config = {}\n",
    "    for i in range(dimension):\n",
    "        api_config[\"dim_\"+str(i)] = {\"type\" : \"real\", \"space\" : \"linear\", \"range\" : (f.lb[0], f.ub[0])}     \n",
    "\n",
    "    min_result = np.zeros(0)\n",
    "    for random_seed in range(5):\n",
    "                \n",
    "        print(\"=\"*20)\n",
    "        print(\"Seed : \", random_seed)\n",
    "        random.seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "        torch.cuda.manual_seed(random_seed)\n",
    "        torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "        # Optimize\n",
    "        AT = AdvancedTurbo(api_config)\n",
    "        AT.optimize(f, num_evals=50, n_suggestions=10)\n",
    "\n",
    "        # Collect Minimum value\n",
    "        fX = AT.turbo.fX\n",
    "        min_result = np.concatenate((min_result, min(fX)))\n",
    "        plot_results[func+'_'+str(random_seed)] = fX.tolist()\n",
    "        \n",
    "    results[func] = min_result.tolist()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbo",
   "language": "python",
   "name": "bbo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
